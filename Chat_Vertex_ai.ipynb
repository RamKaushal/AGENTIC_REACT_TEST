{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-cloud_aiplatform langchain langchain-google-genai langgraph langchain_experimental langchain_google_vertexai"
      ],
      "metadata": {
        "id": "_gbo3Mn-SISw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XVMkQHjR9Yt"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional, Sequence, TypedDict, Dict, List, Union, Any\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.models import load_model\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "\n",
        "from langchain_core.messages import (\n",
        "    BaseMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage,\n",
        "    SystemMessage,\n",
        ")\n",
        "from langchain_core.language_models import BaseChatModel, LLM\n",
        "from langchain_core.outputs import Generation, ChatResult, ChatGeneration\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import Tool, tool\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import (\n",
        "    AgentState,\n",
        "    add_messages,\n",
        "    IsLastStep,\n",
        "    RemainingSteps,\n",
        ")\n",
        "\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "from vertexai import init as vertexai_init\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = None\n",
        "df2 = None\n",
        "coef_global = []\n",
        "XGB_MAPE = None\n",
        "LSTM_MAPE = None\n",
        "\n",
        "@tool\n",
        "def preprocess(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Preprocess the dataframe before passing it to the model.\n",
        "    \"\"\"\n",
        "    global df\n",
        "    try:\n",
        "        df = pd.read_csv(\"/content/Costco_interval_data_lstm.csv\") #PATH_CAHNGE_1\n",
        "        df = df.groupby(\"Date\").agg({\"Call Volume\": \"sum\", \"AHT\": \"mean\"}).reset_index()\n",
        "        df.set_index(\"Date\", inplace=True)\n",
        "        df.sort_index(inplace=True)\n",
        "        df.drop(columns=\"AHT\", inplace=True)\n",
        "    except Exception as e:\n",
        "        return f\"Error in reading and preprocessing df: {str(e)}\"\n",
        "\n",
        "    try:\n",
        "        df.index = pd.to_datetime(df.index, format='mixed')\n",
        "        df[\"day_of_week\"] = df.index.dayofweek\n",
        "        df[\"month\"] = df.index.month\n",
        "        df[\"quarter\"] = df.index.quarter\n",
        "        df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
        "        df[\"day_of_week_sin\"] = np.sin(2 * np.pi * df[\"day_of_week\"] / 7)\n",
        "        df[\"day_of_week_cos\"] = np.cos(2 * np.pi * df[\"day_of_week\"] / 7)\n",
        "        df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "        df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "        df[\"week_of_month\"] = (df.index.day - 1) // 7 + 1\n",
        "\n",
        "        # Add holiday columns\n",
        "        major_holidays = pd.to_datetime([\n",
        "            \"2018-01-01\", \"2018-07-04\", \"2018-11-22\", \"2018-12-25\",\n",
        "            \"2019-01-01\", \"2019-07-04\", \"2019-11-28\", \"2019-12-25\",\n",
        "            \"2020-01-01\", \"2020-07-04\", \"2020-11-26\", \"2020-12-25\",\n",
        "            \"2021-01-01\", \"2021-07-04\", \"2021-11-25\", \"2021-12-25\",\n",
        "            \"2022-01-01\", \"2022-07-04\", \"2022-11-24\", \"2022-12-25\",\n",
        "            \"2023-01-01\", \"2023-07-04\", \"2023-11-23\", \"2023-12-25\",\n",
        "            \"2024-01-01\", \"2024-07-04\", \"2024-11-28\", \"2024-12-25\",\n",
        "            \"2025-01-01\", \"2025-07-04\", \"2025-11-27\", \"2025-12-25\"\n",
        "        ])\n",
        "        minor_holidays = pd.to_datetime([\n",
        "            \"2018-02-19\", \"2018-10-08\", \"2018-12-24\", \"2018-12-31\",\n",
        "            \"2019-02-18\", \"2019-10-14\", \"2019-12-24\", \"2019-12-31\",\n",
        "            \"2020-02-17\", \"2020-10-12\", \"2020-12-24\", \"2020-12-31\",\n",
        "            \"2021-02-15\", \"2021-10-11\", \"2021-12-24\", \"2021-12-31\",\n",
        "            \"2022-02-21\", \"2022-10-10\", \"2022-12-24\", \"2022-12-31\",\n",
        "            \"2023-02-20\", \"2023-10-09\", \"2023-12-24\", \"2023-12-31\",\n",
        "            \"2024-02-19\", \"2024-10-14\", \"2024-12-24\", \"2024-12-31\",\n",
        "            \"2025-02-17\", \"2025-10-13\", \"2025-12-24\", \"2025-12-31\"\n",
        "        ])\n",
        "        positive_holidays = pd.to_datetime([\n",
        "            \"2018-11-23\", \"2018-11-26\", \"2019-11-29\", \"2019-12-02\",\n",
        "            \"2020-11-27\", \"2020-11-30\", \"2021-11-26\", \"2021-11-29\",\n",
        "            \"2022-11-25\", \"2022-11-28\", \"2023-11-24\", \"2023-11-27\",\n",
        "            \"2024-11-29\", \"2024-12-02\", \"2025-11-28\", \"2025-12-01\"\n",
        "        ])\n",
        "        df[\"is_major_holiday\"] = df.index.isin(major_holidays).astype(int)\n",
        "        df[\"is_minor_holiday\"] = df.index.isin(minor_holidays).astype(int)\n",
        "        df[\"is_positive_holiday\"] = df.index.isin(positive_holidays).astype(int)\n",
        "\n",
        "        # MOB Feature Engineering\n",
        "        df[\"Year\"] = df.index.year\n",
        "        df[\"Month\"] = df.index.month\n",
        "\n",
        "        new_accounts_df = pd.read_csv(r\"/content/Costco_new_accounts.csv\", parse_dates=[\"Date\"]) #PATH_CAHNGE_2\n",
        "        mob_cols = [f\"MOB_{i}\" for i in range(24)] + [\"MOB_>24\"]\n",
        "        result_df = pd.DataFrame(columns=[\"Date\"] + mob_cols)\n",
        "        result_df[\"Date\"] = new_accounts_df[\"Date\"]\n",
        "\n",
        "        for i in range(len(new_accounts_df)):\n",
        "            values = [0] * len(mob_cols)\n",
        "            values[0] = new_accounts_df.loc[i, \"New_Accounts\"]\n",
        "            for j in range(1, 24):\n",
        "                if i - j >= 0:\n",
        "                    values[j] = result_df.loc[i - 1, f\"MOB_{j - 1}\"]\n",
        "            if i - 23 >= 0:\n",
        "                values[-1] = result_df.loc[i - 1, \"MOB_>24\"] + result_df.loc[i - 1, \"MOB_23\"]\n",
        "            result_df.loc[i, mob_cols] = values\n",
        "\n",
        "        result_df.index = pd.to_datetime(result_df[\"Date\"])\n",
        "        result_df.drop(columns=\"Date\", inplace=True)\n",
        "        result_df[\"Year\"] = result_df.index.year\n",
        "        result_df[\"Month\"] = result_df.index.month\n",
        "\n",
        "        df = df.merge(result_df, on=[\"Year\", \"Month\"], how=\"left\").set_index(df.index)\n",
        "        df.drop(columns=[\"Year\", \"Month\"], inplace=True)\n",
        "    except Exception as e:\n",
        "        return f\"Error in feature engineering: {str(e)}\"\n",
        "\n",
        "    return \"âœ… Preprocessing completed successfully.\"\n",
        "\n",
        "tools = [preprocess]\n",
        "#ADD CREDENTIALS LINE HERE\n",
        "llm = ChatVertexAI(                            #LLM_OBJECT_CHANGE\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    project=\"agentic-454612\",\n",
        "    location=\"us-central1\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    credentials=credentials\n",
        ")\n",
        "bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"agent\", agent_node)\n",
        "graph.set_entry_point(\"agent\")\n",
        "\n",
        "\n",
        "runnable = graph.compile()\n",
        "prompt = \"Preprocess the dataframe 'df'\"\n",
        "output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "print(\"\\nFinal output from agent:\\n\")\n",
        "for msg in output[\"messages\"]:\n",
        "    if hasattr(msg, \"name\"):\n",
        "        print(f\"[TOOL: {msg.name}] {msg.content}\")"
      ],
      "metadata": {
        "id": "Ihzf9JWVSL-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nasl1FfSL8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDVCpudeSL5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5w49Je-ZSL2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWMRI4a3SLz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAwco19WSLxN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}