{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyreadstat google-cloud_aiplatform langchain langchain-google-genai langgraph langchain_experimental langchain_google_vertexai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FdRF0ROgjgpz",
        "outputId": "8931012f-2f7d-40b6-c5f8-3dc21b50508c"
      },
      "id": "FdRF0ROgjgpz",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: google-cloud_aiplatform in /usr/local/lib/python3.11/dist-packages (1.105.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain_google_vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.27-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyreadstat) (2.2.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud_aiplatform) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (3.35.1)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (1.27.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (4.14.1)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud_aiplatform) (0.17.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: bottleneck<2.0.0,>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (1.4.2)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.28.1)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_google_vertexai)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.6 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.11.0)\n",
            "Collecting pyarrow<20.0.0,>=19.0.1 (from langchain_google_vertexai)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting validators<1,>=0.22.0 (from langchain_google_vertexai)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck<2.0.0,>=1.4.2->langchain_google_vertexai) (2.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud_aiplatform) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud_aiplatform) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud_aiplatform) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud_aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud_aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud_aiplatform) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud_aiplatform) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud_aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud_aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud_aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud_aiplatform) (1.7.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud_aiplatform) (4.9.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud_aiplatform) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud_aiplatform) (15.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.14)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->pyreadstat) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud_aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud_aiplatform) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud_aiplatform) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud_aiplatform) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud_aiplatform) (0.6.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud_aiplatform) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_google_genai-2.1.8-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.6.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.9/151.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_vertexai-2.0.27-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, validators, python-dotenv, pyarrow, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph, langchain_google_vertexai, langchain-community, langchain_experimental\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-google-genai-2.1.8 langchain_experimental-0.3.4 langchain_google_vertexai-2.0.27 langgraph-0.6.1 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.1 langgraph-sdk-0.2.0 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 pyarrow-19.0.1 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 validators-0.35.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pyarrow"
                ]
              },
              "id": "2082c8b4e32f463bb12899bf3f6ba707"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/GEMINI_JSON_ACTIVE.json\""
      ],
      "metadata": {
        "id": "aON6wdx6tT6Q"
      },
      "id": "aON6wdx6tT6Q",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.oauth2 import service_account\n",
        "from langchain_google_vertexai.chat_models import ChatVertexAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Load credentials explicitly from service account file\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    \"/content/GEMINI_JSON_ACTIVE.json\"\n",
        ")\n",
        "\n",
        "# Initialize ChatVertexAI with explicit credentials\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    project=\"steady-bonsai-467007-g0\",\n",
        "    location=\"us-central1\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    credentials=credentials  # ✅ This overrides the default fallback\n",
        ")\n",
        "\n",
        "llm.invoke(\"HI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRxHSUGRtTwr",
        "outputId": "b896b9e8-e429-45b3-b138-2a534c75a208"
      },
      "id": "QRxHSUGRtTwr",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 1, 'candidates_token_count': 9, 'total_token_count': 602, 'prompt_tokens_details': [{'modality': 1, 'token_count': 1}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 9}], 'thoughts_token_count': 592, 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -10.322870890299479, 'model_name': 'gemini-2.5-pro'}, id='run--34911bec-a419-4dc6-9c3a-5a78997172cd-0', usage_metadata={'input_tokens': 1, 'output_tokens': 9, 'total_tokens': 602, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 592}})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "c25a9bd4-f996-44a4-917a-33863bfc4abd",
      "metadata": {
        "scrolled": true,
        "id": "c25a9bd4-f996-44a4-917a-33863bfc4abd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import  MinMaxScaler, StandardScaler\n",
        "import pyreadstat\n",
        "from tensorflow.keras.models import  Model, Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Flatten, Layer, Input, LayerNormalization, BatchNormalization, Add, Activation, Permute, Multiply, Lambda\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from tensorflow.keras.initializers import HeUniform\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import load_model\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Optional, Sequence, TypedDict, Dict, List, Union, Any\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.models import load_model\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "\n",
        "from langchain_core.messages import (\n",
        "    BaseMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage,\n",
        "    SystemMessage,\n",
        ")\n",
        "from langchain_core.language_models import BaseChatModel, LLM\n",
        "from langchain_core.outputs import Generation, ChatResult, ChatGeneration\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import Tool, tool\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import (\n",
        "    AgentState,\n",
        "    add_messages,\n",
        "    IsLastStep,\n",
        "    RemainingSteps,\n",
        ")\n",
        "\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "from vertexai import init as vertexai_init\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Dict, Any\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Agentic_AI(BaseModel):\n",
        "    Corecast: Optional[Dict[str, Any]] = None\n",
        "    FestivCast: Optional[Dict[str, Any]] = None\n",
        "    SesoCast: Optional[Dict[str, Any]] = None\n",
        "\n",
        "###########################################################################################################################\n",
        "#####################################...............CORECAST..............#################################################\n",
        "###########################################################################################################################\n",
        "def Corecast(state:Agentic_AI ):\n",
        "  @tool\n",
        "  def preprocess(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Preprocess the call volume dataset for modeling.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: Preprocessed and feature-engineered DataFrame ready for LSTM modeling,\n",
        "                        with relevant columns encoded and 'REPORT_DT' set as the index.\n",
        "      \"\"\"\n",
        "      global holidays_df,model_data,model_data_encoded\n",
        "      holidays_df = pd.read_csv(r\"/content/Holiday.csv\")                   ###PATH_CHANGE\n",
        "      model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")  ###PATH_CHANGE\n",
        "      holidays_df['Date'] = pd.to_datetime(holidays_df['Date'],dayfirst=True)\n",
        "      model_data = pd.merge(model_data, holidays_df[['Date', 'Holiday']],\n",
        "                            left_on='REPORT_DT', right_on='Date', how='left')\n",
        "      model_data.drop(columns=['Date'], inplace=True)\n",
        "      model_data['Holiday'] = model_data['Holiday'].fillna('No Holiday')\n",
        "      model_data.sort_values(by='REPORT_DT').reset_index()\n",
        "      model_data.set_index('REPORT_DT', inplace=True)\n",
        "      # model_data = model_data.drop(columns=['index'], axis = 1)\n",
        "      # Ensure that columns are numeric\n",
        "      model_data['DAY_OF_WEEK'] = model_data.index.dayofweek\n",
        "      model_data['DAY_OF_MONTH'] = pd.to_numeric(model_data['DAY_OF_MONTH'], errors='coerce')\n",
        "      model_data['MONTH'] = pd.to_numeric(model_data['MONTH'], errors='coerce')\n",
        "      model_data['QUARTER'] = pd.to_numeric(model_data['QUARTER'], errors='coerce')\n",
        "      # Encode DAY_OF_WEEK (1 to 7)\n",
        "      model_data['DAY_OF_WEEK_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      model_data['DAY_OF_WEEK_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      # Encode DAY_OF_MONTH (1 to 31)\n",
        "      model_data['DAY_OF_MONTH_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      model_data['DAY_OF_MONTH_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      # Encode MONTH (1 to 12)\n",
        "      model_data['MONTH_SIN'] = np.sin(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      model_data['MONTH_COS'] = np.cos(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      # Encode QUARTER (1 to 4)\n",
        "      model_data['QUARTER_SIN'] = np.sin(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      model_data['QUARTER_COS'] = np.cos(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      # Encode extra\n",
        "      model_data['is_sunday'] = (model_data.index.dayofweek == 6).astype(int)\n",
        "      model_data['is_monday'] = (model_data.index.dayofweek == 0).astype(int)\n",
        "      model_data['is_weekend'] = (model_data.index.dayofweek >= 5).astype(int)\n",
        "      encoding = model_data.groupby('Holiday')['TOTAL_OFFERED_CALL_VOLUME'].mean().to_dict()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['Holiday'].map(encoding)\n",
        "      default_value = model_data['TOTAL_OFFERED_CALL_VOLUME'].mean()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['HOLIDAY_ENCODED'].fillna(default_value)\n",
        "      model_data_encoded = model_data.drop(columns=['DAY_OF_WEEK','DAY_OF_MONTH',\"YEAR\",\"QUARTER\",\"Holiday\",\"MONTH\"])\n",
        "      return model_data_encoded\n",
        "\n",
        "  @tool\n",
        "  def LSTM_Prediction(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Predicts future call volumes using a pre-trained LSTM model.\n",
        "\n",
        "      This function takes the preprocessed and encoded data, creates input sequences,\n",
        "      loads a trained LSTM model, and returns a 180-day forecast.\n",
        "\n",
        "      Args:\n",
        "          model_data_encoded (pd.DataFrame): The DataFrame with engineered and scaled features,\n",
        "                                            output from the `preprocess` function.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame containing 180 days of future dates and corresponding forecasted\n",
        "                        'TOTAL_OFFERED_CALL_VOLUME' values.\n",
        "      \"\"\"\n",
        "      global forecast_df\n",
        "      # Define input features and target\n",
        "      feature_cols = ['DAY_OF_WEEK_SIN', 'DAY_OF_WEEK_COS',\n",
        "                      'DAY_OF_MONTH_SIN', 'DAY_OF_MONTH_COS', 'MONTH_SIN', 'MONTH_COS',\n",
        "                      'QUARTER_SIN', 'QUARTER_COS', 'HOLIDAY_ENCODED']\n",
        "      target_col = 'TOTAL_OFFERED_CALL_VOLUME'\n",
        "      model_data_encoded_scaled = model_data_encoded.copy()\n",
        "      scaler = MinMaxScaler()\n",
        "      model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
        "          model_data_encoded_scaled[['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']])\n",
        "\n",
        "      def create_sequences(data, seq_length, horizon):\n",
        "          X= []\n",
        "          for i in range(len(data) - seq_length - horizon + 1):\n",
        "              X.append(data[i:i + seq_length])\n",
        "          return np.array(X)\n",
        "\n",
        "      X_train= create_sequences(model_data_encoded_scaled, 360, 180)\n",
        "      model = tf.keras.models.load_model(r\"/content/Agentic_AI_LSTM_v1.h5\") ###PATH_CHANGE\n",
        "      predictions = model.predict(X_train)\n",
        "      predictions_rescaled = scaler.data_min_[0] + predictions * (scaler.data_max_[0] - scaler.data_min_[0])\n",
        "      predictions_rescaled = predictions_rescaled[0]\n",
        "      start_date = model_data_encoded.index[-1] + pd.Timedelta(days=1)\n",
        "      date_range = pd.date_range(start=start_date, periods=180, freq='D')\n",
        "      forecast_df = pd.DataFrame({'Date':date_range, 'Forecast':predictions_rescaled})\n",
        "      return forecast_df\n",
        "\n",
        "  @tool\n",
        "  def Last_week_Mape(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Calculates the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes\n",
        "      for the last 7 days (after forecasting 180 days using data excluding the final 14 days).\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: DataFrame containing date, forecast, actual call volume, and calculated MAPE\n",
        "                        for the overlapping 7-day period.\n",
        "      \"\"\"\n",
        "      global holidays_df,model_data,forecast_last_week_mape\n",
        "      holidays_df = pd.read_csv(r\"/content/Holiday.csv\") ###PATH_CHANGE\n",
        "      model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")  ###PATH_CHANGE\n",
        "      model_data = model_data.iloc[:-7]\n",
        "      holidays_df['Date'] = pd.to_datetime(holidays_df['Date'],dayfirst=True)\n",
        "      model_data = pd.merge(model_data, holidays_df[['Date', 'Holiday']],\n",
        "                            left_on='REPORT_DT', right_on='Date', how='left')\n",
        "      model_data.drop(columns=['Date'], inplace=True)\n",
        "      model_data['Holiday'] = model_data['Holiday'].fillna('No Holiday')\n",
        "      model_data.sort_values(by='REPORT_DT').reset_index()\n",
        "      model_data.set_index('REPORT_DT', inplace=True)\n",
        "      # model_data = model_data.drop(columns=['index'], axis = 1)\n",
        "      # Ensure that columns are numeric\n",
        "      model_data['DAY_OF_WEEK'] = model_data.index.dayofweek\n",
        "      model_data['DAY_OF_MONTH'] = pd.to_numeric(model_data['DAY_OF_MONTH'], errors='coerce')\n",
        "      model_data['MONTH'] = pd.to_numeric(model_data['MONTH'], errors='coerce')\n",
        "      model_data['QUARTER'] = pd.to_numeric(model_data['QUARTER'], errors='coerce')\n",
        "      # Encode DAY_OF_WEEK (1 to 7)\n",
        "      model_data['DAY_OF_WEEK_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      model_data['DAY_OF_WEEK_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      # Encode DAY_OF_MONTH (1 to 31)\n",
        "      model_data['DAY_OF_MONTH_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      model_data['DAY_OF_MONTH_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      # Encode MONTH (1 to 12)\n",
        "      model_data['MONTH_SIN'] = np.sin(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      model_data['MONTH_COS'] = np.cos(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      # Encode QUARTER (1 to 4)\n",
        "      model_data['QUARTER_SIN'] = np.sin(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      model_data['QUARTER_COS'] = np.cos(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      # Encode extra\n",
        "      model_data['is_sunday'] = (model_data.index.dayofweek == 6).astype(int)\n",
        "      model_data['is_monday'] = (model_data.index.dayofweek == 0).astype(int)\n",
        "      model_data['is_weekend'] = (model_data.index.dayofweek >= 5).astype(int)\n",
        "      encoding = model_data.groupby('Holiday')['TOTAL_OFFERED_CALL_VOLUME'].mean().to_dict()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['Holiday'].map(encoding)\n",
        "      default_value = model_data['TOTAL_OFFERED_CALL_VOLUME'].mean()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['HOLIDAY_ENCODED'].fillna(default_value)\n",
        "      model_data_encoded = model_data.drop(columns=['DAY_OF_WEEK','DAY_OF_MONTH',\"YEAR\",\"QUARTER\",\"Holiday\",\"MONTH\"])\n",
        "          # Define input features and target\n",
        "      feature_cols = ['DAY_OF_WEEK_SIN', 'DAY_OF_WEEK_COS',\n",
        "                      'DAY_OF_MONTH_SIN', 'DAY_OF_MONTH_COS', 'MONTH_SIN', 'MONTH_COS',\n",
        "                      'QUARTER_SIN', 'QUARTER_COS', 'HOLIDAY_ENCODED']\n",
        "      target_col = 'TOTAL_OFFERED_CALL_VOLUME'\n",
        "      model_data_encoded_scaled = model_data_encoded.copy()\n",
        "      scaler = MinMaxScaler()\n",
        "      model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
        "          model_data_encoded_scaled[['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']])\n",
        "\n",
        "      def create_sequences(data, seq_length, horizon):\n",
        "          X= []\n",
        "          for i in range(len(data) - seq_length - horizon + 1):\n",
        "              X.append(data[i:i + seq_length])\n",
        "          return np.array(X)\n",
        "      X_train= create_sequences(model_data_encoded_scaled, 360, 180)\n",
        "      model = tf.keras.models.load_model(r\"/content/Agentic_AI_LSTM_v1.h5\") ###PATH_CHANGE\n",
        "      predictions = model.predict(X_train)\n",
        "      predictions_rescaled = scaler.data_min_[0] + predictions * (scaler.data_max_[0] - scaler.data_min_[0])\n",
        "      predictions_rescaled = predictions_rescaled[0]\n",
        "      start_date = model_data_encoded.index[-1] + pd.Timedelta(days=1)\n",
        "      date_range = pd.date_range(start=start_date, periods=180, freq='D')\n",
        "      forecast_df = pd.DataFrame({'Date':date_range, 'Forecast':predictions_rescaled})\n",
        "      model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")  ###PATH_CHANGE\n",
        "      model_data = model_data.reset_index()\n",
        "      model_data.rename(columns={'REPORT_DT':'Date'},inplace=True)\n",
        "      forecast_last_week = forecast_df.merge(model_data[['Date','TOTAL_OFFERED_CALL_VOLUME']],on=['Date'],how='inner')\n",
        "      forecast_last_week['MAPE'] = (abs(forecast_last_week['TOTAL_OFFERED_CALL_VOLUME'] - forecast_last_week['Forecast'])\n",
        "                                    /forecast_last_week['TOTAL_OFFERED_CALL_VOLUME'])*100\n",
        "      forecast_last_week_mape = forecast_last_week['MAPE'].mean()\n",
        "\n",
        "      return forecast_last_week_mape\n",
        "\n",
        "  tools = [preprocess, LSTM_Prediction,Last_week_Mape]\n",
        "  llm = ChatVertexAI(\n",
        "      model=\"gemini-2.5-pro\",\n",
        "      project=\"steady-bonsai-467007-g0\",\n",
        "      location=\"us-central1\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0.7,\n",
        "      credentials=credentials\n",
        "  )\n",
        "  bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "  agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "  graph = StateGraph(AgentState)\n",
        "  graph.add_node(\"agent\", agent_node)\n",
        "  graph.set_entry_point(\"agent\")\n",
        "\n",
        "  runnable = graph.compile()\n",
        "  prompt = \"Preprocesses the dataframe with  'model_data' and Predicts future call volumes using a pre-trained LSTM model with 'model_data_encoded' \"\n",
        "  output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "  prompt2 = \"Calculate the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes for the last 7 days with 'model_data' \"\n",
        "  output2 = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt2}]})\n",
        "\n",
        "  print(\"\\nFinal output from agent:\\n\")\n",
        "  for msg in output[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "\n",
        "  for msg in output2[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "  return None\n",
        "\n",
        "###########################################################################################################################\n",
        "#####################################...............FestivCast..............###############################################\n",
        "###########################################################################################################################\n",
        "def FestivCast(state:Agentic_AI):\n",
        "  @tool\n",
        "  def identify_holidays(input: str) -> str:\n",
        "\n",
        "    \"\"\"\n",
        "    Identify holiday dates in the forecast dataset and compare forecasted call volumes with the average actuals\n",
        "    for the same weekday over the past 3 weeks to estimate the forecasted holiday impact.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame showing:\n",
        "            - Holiday date\n",
        "            - Holiday name\n",
        "            - Day of the week\n",
        "            - 3-week average actuals for the same weekday\n",
        "            - Forecasted volume\n",
        "            - Percentage difference indicating the forecasted impact\n",
        "    \"\"\"\n",
        "    global forecast_df, model_data, holidays_df,forecast_holiday_impact\n",
        "    df_actual = model_data.copy()\n",
        "    df_holidays = holidays_df.copy()\n",
        "    df_forecast = forecast_df.copy()\n",
        "    df_actual.rename(columns={'REPORT_DT':'Date','TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "    df_forecast['Date'] = pd.to_datetime(df_forecast['Date'])\n",
        "    df_actual['Date'] = pd.to_datetime(df_actual['Date'])\n",
        "    df_holidays['Date'] = pd.to_datetime(df_holidays['Date'],dayfirst=True)\n",
        "    df_forecast['day_of_week'] = pd.to_datetime(df_forecast['Date']).dt.day_name()\n",
        "    df_actual['day_of_week'] = pd.to_datetime(df_actual['Date']).dt.day_name()\n",
        "    holiday_forecast = df_forecast.merge(df_holidays, left_on = \"Date\", right_on = \"Date\", how = \"inner\")\n",
        "    holiday_forecast = holiday_forecast[[\"Date\",\"Holiday\",\"day_of_week\",\"Forecast\"]]\n",
        "    holiday_forecast.rename(columns={\"day_of_week\":\"Day of Week\"}, inplace = True)\n",
        "    dow_averages = []\n",
        "    for date, dow in zip(holiday_forecast['Date'], holiday_forecast['Day of Week']):\n",
        "        start_date = date - pd.Timedelta(weeks=3)\n",
        "        filtered = df_actual[(df_actual['Date'] < date) & (df_actual['Date'] >= start_date)]\n",
        "        avg = filtered[filtered['day_of_week'] == dow]['Call Volume'].mean()\n",
        "        dow_averages.append(avg)\n",
        "    holiday_forecast['dow_avg_3w'] = dow_averages\n",
        "    holiday_forecast['Impact_Captured'] = round(\n",
        "        (holiday_forecast['Forecast'] - holiday_forecast['dow_avg_3w']) /\n",
        "        holiday_forecast['dow_avg_3w'] * 100, 2\n",
        "    )\n",
        "    forecast_holiday_impact = holiday_forecast.copy()\n",
        "    return forecast_holiday_impact\n",
        "\n",
        "  @tool\n",
        "  def holiday_impact(input: str) -> str:\n",
        "\n",
        "      \"\"\"\n",
        "      Evaluate the *actual* impact of holidays on call volume by comparing actuals to a 3-week weekday average.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A summarized DataFrame grouped by holiday, showing:\n",
        "              - Holiday name\n",
        "              - Mean actual call volume on the holiday\n",
        "              - Mean percentage difference compared to normal same-day-of-week volumes (Actual Impact)\n",
        "      \"\"\"\n",
        "      global model_data, holidays_df,historic_holiday_impact\n",
        "      df_actuals = model_data.copy()\n",
        "      df_holidays = holidays_df.copy()\n",
        "      df_actuals.rename(columns={'REPORT_DT':'Date','TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "      df_forecast = forecast_df.copy()\n",
        "      df_actuals['Date'] = pd.to_datetime(df_actuals['Date'])\n",
        "      df_holidays['Date'] = pd.to_datetime(df_holidays['Date'],dayfirst=True)\n",
        "      merged_df = pd.merge(df_actuals, df_holidays[['Date', \"Holiday\"]], left_on='Date', right_on='Date', how='left')\n",
        "      # Fill NaN values in the 'Holiday' column with 'Normal Day'\n",
        "      merged_df['Holiday'] = merged_df['Holiday'].fillna('Normal Day')\n",
        "      dow_averages = []\n",
        "      for date, dow in zip(merged_df['Date'], merged_df['DAY_OF_WEEK']):\n",
        "          start_date = date - pd.Timedelta(weeks=3)\n",
        "          filtered = merged_df[(merged_df['Date'] < date) & (merged_df['Date'] >= start_date)]\n",
        "          avg = filtered[filtered['DAY_OF_WEEK'] == dow]['Call Volume'].mean()\n",
        "          dow_averages.append(avg)\n",
        "      merged_df['dow_avg_3w'] = dow_averages\n",
        "      merged_df['Actual_Impact'] = round((merged_df['Call Volume']-merged_df['dow_avg_3w'])/merged_df['dow_avg_3w']*100,2)\n",
        "      historic_holiday_impact = merged_df.groupby(\"Holiday\",as_index = False).agg({\"Actual_Impact\":\"mean\",\"Call Volume\":\"mean\"}).reset_index(drop=True)\n",
        "      return historic_holiday_impact\n",
        "\n",
        "  @tool\n",
        "  def final_adjustment(input: str) -> str:\n",
        "\n",
        "      \"\"\"\n",
        "      Performs a final adjustment on the holiday-forecasted call volumes by incorporating\n",
        "      the difference between actual historical impact and the impact already captured.\n",
        "      \"\"\"\n",
        "      global adjust_df\n",
        "      adjust_df = forecast_holiday_impact.merge(historic_holiday_impact, on=\"Holiday\", how = \"left\")\n",
        "      adjust_df['Impact_Not_Captured'] = adjust_df['Actual_Impact'] - adjust_df['Impact_Captured']\n",
        "      adjust_df['FestiVcast_Adjusted_Forecast'] = np.where(adjust_df['Impact_Not_Captured']>0, adjust_df['Forecast']*(1+(adjust_df['Impact_Not_Captured'])/100), adjust_df['Forecast'])\n",
        "      return adjust_df\n",
        "\n",
        "\n",
        "  tools = [final_adjustment, holiday_impact,identify_holidays]\n",
        "  llm = ChatVertexAI(\n",
        "      model=\"gemini-2.5-pro\",\n",
        "      project=\"steady-bonsai-467007-g0\",\n",
        "      location=\"us-central1\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0.7,\n",
        "      credentials=credentials\n",
        "  )\n",
        "  bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "  agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "  graph = StateGraph(AgentState)\n",
        "  graph.add_node(\"agent\", agent_node)\n",
        "  graph.set_entry_point(\"agent\")\n",
        "\n",
        "  runnable = graph.compile()\n",
        "  prompt = \"identify the holidays present in 'forecast_df' and thenEvaluate the actual impact of holidays on call volume and finally  Performs a final adjustment on the holiday-forecasted call volumes\"\n",
        "  output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "  print(\"\\nFinal output from agent:\\n\")\n",
        "  for msg in output[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "  return None\n",
        "\n",
        "###########################################################################################################################\n",
        "#####################################...............SesoCast..............###############################################\n",
        "###########################################################################################################################\n",
        "def Sesocast(state:Agentic_AI):\n",
        "  @tool\n",
        "  def get_historical_periods_dynamic_actual(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Extracts the same date range in previous years from a DataFrame, dynamically determining available years.\n",
        "      Returns:\n",
        "          dict: A dictionary where keys are years and values are DataFrames\n",
        "                containing the corresponding period. Returns an empty dictionary if there are issues.\n",
        "      \"\"\"\n",
        "      global forecast_df, model_data,final_last_28_days\n",
        "      df = model_data.iloc[-28:].copy()\n",
        "      df_history =  model_data.copy()\n",
        "      date_column='Date'\n",
        "      start_date=None\n",
        "      end_date=None\n",
        "\n",
        "      df_history.rename(columns={'REPORT DT':'Date', 'TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "      df[date_column] = pd.to_datetime(df[date_column])\n",
        "      # Determine start and end dates if not provided\n",
        "      if start_date is None or end_date is None:\n",
        "          end_date = df[date_column].max()\n",
        "          start_date = df[date_column].min()\n",
        "      else:\n",
        "          start_date = pd.to_datetime(start_date)\n",
        "          end_date = pd.to_datetime(end_date)\n",
        "      # Calculate the date range\n",
        "      date_range = end_date - start_date\n",
        "      if date_range.days < 0:\n",
        "          print(\"Error: End date is earlier than start date.\")\n",
        "      historical_periods = {}\n",
        "      current_year = end_date.year # Use the end date year as the \"current\" year\n",
        "      available_years = sorted(df_history[date_column].dt.year.unique(), reverse=True)\n",
        "      # Iterate through available years *excluding* the current year\n",
        "      for year in available_years:\n",
        "          if year == current_year:\n",
        "              continue #skip current year\n",
        "          # Calculate the start and end dates for the current year\n",
        "          year_start_date = pd.to_datetime(f'{year}-{start_date.month}-{start_date.day}')\n",
        "          year_end_date = pd.to_datetime(f'{year}-{end_date.month}-{end_date.day}')\n",
        "          # Filter the Dataframe for the current year period\n",
        "          year_df = df_history[(df_history[date_column] >= year_start_date) & (df_history[date_column] <= year_end_date)].copy()\n",
        "          if not year_df.empty:\n",
        "              historical_periods[year] = year_df\n",
        "          else:\n",
        "              print(f'No data found for {year}.')\n",
        "      historical_periods_yearly = pd.DataFrame()\n",
        "      last_28days_dict = historical_periods.copy()\n",
        "      counter = 0\n",
        "      final_last_28_days = pd.DataFrame()\n",
        "      for i in last_28days_dict.keys():\n",
        "          if counter<3:\n",
        "              globals()[f\"last_28days_{i}\"] = last_28days_dict[i]\n",
        "          else:\n",
        "              break\n",
        "          final_last_28_days = pd.concat([final_last_28_days,globals()[f\"last_28days_{i}\"]], ignore_index = True)\n",
        "          final_last_28_days['Year'] = final_last_28_days['Date'].dt.year\n",
        "      return final_last_28_days\n",
        "\n",
        "\n",
        "  @tool\n",
        "  def get_historical_periods_dynamic_forecast(input: str) -> str:\n",
        "\n",
        "      \"\"\"\n",
        "      Forecast is Extracted for the same date range from forecast dataframe, dynamically determining available years.\n",
        "      Returns:\n",
        "          dict: A dictionary where keys are years and values are DataFrames\n",
        "                containing the corresponding period. Returns an empty dictionary if there are issues.\n",
        "      \"\"\"\n",
        "      global forecast_df, model_data,final_next_28_days\n",
        "      df = forecast_df.copy()\n",
        "      df_history =  model_data.copy()\n",
        "      date_column='Date'\n",
        "      start_date=None\n",
        "      end_date=None\n",
        "\n",
        "      df_history.rename(columns={'REPORT_DT': 'Date', 'TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "      df[date_column] = pd.to_datetime(df[date_column])\n",
        "      # Determine start and end dates if not provided\n",
        "      if start_date is None or end_date is None:\n",
        "          end_date = df[date_column].max()\n",
        "          start_date = df[date_column].min()\n",
        "      else:\n",
        "          start_date = pd.to_datetime(start_date)\n",
        "          end_date = pd.to_datetime(end_date)\n",
        "      # Calculate the date range\n",
        "      date_range = end_date - start_date\n",
        "      if date_range.days < 0:\n",
        "          print(\"Error: End date is earlier than start date.\")\n",
        "      historical_periods = {}\n",
        "      current_year = end_date.year # Use the end_date year as the \"current\" year\n",
        "      available_years = sorted(df_history[date_column].dt.year.unique(), reverse=True)\n",
        "      # Iterate through available years excluding the \"current\" year\n",
        "      for year in available_years:\n",
        "          if year == current_year:\n",
        "              continue #skip current year\n",
        "          year_start_date = pd.to_datetime(f'{year}-{start_date.month}-{start_date.day}')\n",
        "          year_end_date = pd.to_datetime(f'{year}-{end_date.month}-{end_date.day}')\n",
        "          year_df = df_history[(df_history[date_column] >= year_start_date) & (df_history[date_column] <= year_end_date)].copy()\n",
        "          if not year_df.empty:\n",
        "              historical_periods[year] = year_df\n",
        "      else:\n",
        "          historical_periods[year] = pd.DataFrame()\n",
        "      next_28days_dict = historical_periods.copy()\n",
        "      counter = 0\n",
        "      # Initialize an empty DataFrame\n",
        "      final_next_28_days = pd.DataFrame()\n",
        "      for i in next_28days_dict.keys():\n",
        "          if counter<3:\n",
        "              globals()[f\"next_28days_{i}\"] = next_28days_dict[i]\n",
        "              counter+=1\n",
        "          else:\n",
        "              break\n",
        "          final_next_28_days = pd.concat([final_next_28_days,globals()[f\"next_28days_{i}\"]], ignore_index = True)\n",
        "          final_next_28_days['Year'] = final_next_28_days['Date'].dt.year\n",
        "      return final_next_28_days\n",
        "\n",
        "  @tool\n",
        "  def Final_adjustment_Seso(input: str) -> str:\n",
        "    \"\"\"\n",
        "      Applies a last-mile seasonal adjustment to the forecasted call volumes based on\n",
        "      day-of-week (DOW) trends observed in the last 28 days vs the upcoming 28 days.\n",
        "    \"\"\"\n",
        "    global forecast_df, model_data,final_next_28_days,forecast_merged,final_last_28_days\n",
        "    final_next_28_dow_avg = final_next_28_days.groupby([\"Year\",\"DAY_OF_WEEK\"], as_index = False).agg({\"Call Volume\":\"mean\"})\n",
        "    final_next_28_dow_avg = final_next_28_dow_avg.rename(columns = {'Call Volume':'actual_offered_next'})\n",
        "    final_last_28_dow_avg = final_last_28_days.groupby([\"Year\",\"DAY_OF_WEEK\"], as_index = False).agg({\"Call Volume\":\"mean\"})\n",
        "    final_last_28_dow_avg = final_last_28_dow_avg.rename(columns = {'Call Volume':'actual_offered_last'})\n",
        "    final_seasonal_comparison_df = final_next_28_dow_avg.merge(final_last_28_dow_avg, on = [\"Year\",\"DAY_OF_WEEK\"], how = \"inner\")\n",
        "    final_seasonal_comparison_df[\"Seasonal_Factor\"] = (final_seasonal_comparison_df[\"actual_offered_next\"]/ final_seasonal_comparison_df[\"actual_offered_last\"])\n",
        "    final_seasonality_dim = final_seasonal_comparison_df.groupby([\"DAY_OF_WEEK\"], as_index = False).agg({\"Seasonal_Factor\":\"mean\"})\n",
        "\n",
        "    forecast_df['DAY_OF_WEEK'] = pd.to_datetime(forecast_df['Date']).dt.day_name()\n",
        "\n",
        "    forecast_merged = forecast_df.merge(final_seasonality_dim,on=['DAY_OF_WEEK'],how='inner')\n",
        "    forecast_merged['LM_Seasonal_Adjustment'] = forecast_merged['Forecast'] * forecast_merged['Seasonal_Factor']\n",
        "    forecast_merged = forecast_merged[['Date','DAY_OF_WEEK','Forecast','Seasonal_Factor','LM_Seasonal_Adjustment']]\n",
        "    return forecast_merged\n",
        "\n",
        "\n",
        "  tools = [Final_adjustment_Seso, get_historical_periods_dynamic_forecast,get_historical_periods_dynamic_actual]\n",
        "  llm = ChatVertexAI(\n",
        "      model=\"gemini-2.5-pro\",\n",
        "      project=\"steady-bonsai-467007-g0\",\n",
        "      location=\"us-central1\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0.7,\n",
        "      credentials=credentials\n",
        "  )\n",
        "  bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "  agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "  graph = StateGraph(AgentState)\n",
        "  graph.add_node(\"agent\", agent_node)\n",
        "  graph.set_entry_point(\"agent\")\n",
        "\n",
        "  runnable = graph.compile()\n",
        "  prompt = \"extract the same date range in previous years from 'model_data' and also  Extract for the same date range from forecast dataframe 'forecast_df' and finally Apply a last-mile seasonal adjustment to the forecasted call volumes \"\n",
        "  output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "  print(\"\\nFinal output from agent:\\n\")\n",
        "  for msg in output[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "  return None\n",
        "\n",
        "################################################################################################################################################\n",
        "graph = StateGraph(Agentic_AI)\n",
        "graph.add_node(\"Corecast\", Corecast)\n",
        "graph.add_node(\"Festivcast\", FestivCast)\n",
        "graph.add_node(\"SesoCast\", Sesocast)\n",
        "graph.set_entry_point(\"Corecast\")\n",
        "graph.add_edge(\"Corecast\",\"Festivcast\")\n",
        "graph.add_edge(\"Corecast\",\"SesoCast\")\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "runnable = app.invoke({})"
      ],
      "metadata": {
        "id": "aJ2kkXMHBdIg"
      },
      "id": "aJ2kkXMHBdIg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def preprocess(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Preprocess the call volume dataset for modeling.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed and feature-engineered DataFrame ready for LSTM modeling,\n",
        "                      with relevant columns encoded and 'REPORT_DT' set as the index.\n",
        "    \"\"\"\n",
        "    global holidays_df,model_data,model_data_encoded\n",
        "    holidays_df = pd.read_csv(r\"/content/Holiday.csv\")\n",
        "    model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")\n",
        "    holidays_df['Date'] = pd.to_datetime(holidays_df['Date'],dayfirst=True)\n",
        "    model_data = pd.merge(model_data, holidays_df[['Date', 'Holiday']],\n",
        "                          left_on='REPORT_DT', right_on='Date', how='left')\n",
        "    model_data.drop(columns=['Date'], inplace=True)\n",
        "    model_data['Holiday'] = model_data['Holiday'].fillna('No Holiday')\n",
        "    model_data.sort_values(by='REPORT_DT').reset_index()\n",
        "    model_data.set_index('REPORT_DT', inplace=True)\n",
        "    # model_data = model_data.drop(columns=['index'], axis = 1)\n",
        "    # Ensure that columns are numeric\n",
        "    model_data['DAY_OF_WEEK'] = model_data.index.dayofweek\n",
        "    model_data['DAY_OF_MONTH'] = pd.to_numeric(model_data['DAY_OF_MONTH'], errors='coerce')\n",
        "    model_data['MONTH'] = pd.to_numeric(model_data['MONTH'], errors='coerce')\n",
        "    model_data['QUARTER'] = pd.to_numeric(model_data['QUARTER'], errors='coerce')\n",
        "    # Encode DAY_OF_WEEK (1 to 7)\n",
        "    model_data['DAY_OF_WEEK_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "    model_data['DAY_OF_WEEK_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "    # Encode DAY_OF_MONTH (1 to 31)\n",
        "    model_data['DAY_OF_MONTH_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "    model_data['DAY_OF_MONTH_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "    # Encode MONTH (1 to 12)\n",
        "    model_data['MONTH_SIN'] = np.sin(2 * np.pi * model_data['MONTH'] / 12)\n",
        "    model_data['MONTH_COS'] = np.cos(2 * np.pi * model_data['MONTH'] / 12)\n",
        "    # Encode QUARTER (1 to 4)\n",
        "    model_data['QUARTER_SIN'] = np.sin(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "    model_data['QUARTER_COS'] = np.cos(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "    # Encode extra\n",
        "    model_data['is_sunday'] = (model_data.index.dayofweek == 6).astype(int)\n",
        "    model_data['is_monday'] = (model_data.index.dayofweek == 0).astype(int)\n",
        "    model_data['is_weekend'] = (model_data.index.dayofweek >= 5).astype(int)\n",
        "    encoding = model_data.groupby('Holiday')['TOTAL_OFFERED_CALL_VOLUME'].mean().to_dict()\n",
        "    model_data['HOLIDAY_ENCODED'] = model_data['Holiday'].map(encoding)\n",
        "    default_value = model_data['TOTAL_OFFERED_CALL_VOLUME'].mean()\n",
        "    model_data['HOLIDAY_ENCODED'] = model_data['HOLIDAY_ENCODED'].fillna(default_value)\n",
        "    model_data_encoded = model_data.drop(columns=['DAY_OF_WEEK','DAY_OF_MONTH',\"YEAR\",\"QUARTER\",\"Holiday\",\"MONTH\"])\n",
        "    return model_data_encoded\n",
        "\n",
        "@tool\n",
        "def LSTM_Prediction(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Predicts future call volumes using a pre-trained LSTM model.\n",
        "\n",
        "    This function takes the preprocessed and encoded data, creates input sequences,\n",
        "    loads a trained LSTM model, and returns a 180-day forecast.\n",
        "\n",
        "    Args:\n",
        "        model_data_encoded (pd.DataFrame): The DataFrame with engineered and scaled features,\n",
        "                                           output from the `preprocess` function.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing 180 days of future dates and corresponding forecasted\n",
        "                      'TOTAL_OFFERED_CALL_VOLUME' values.\n",
        "    \"\"\"\n",
        "    global forecast_df\n",
        "    # Define input features and target\n",
        "    feature_cols = ['DAY_OF_WEEK_SIN', 'DAY_OF_WEEK_COS',\n",
        "                    'DAY_OF_MONTH_SIN', 'DAY_OF_MONTH_COS', 'MONTH_SIN', 'MONTH_COS',\n",
        "                    'QUARTER_SIN', 'QUARTER_COS', 'HOLIDAY_ENCODED']\n",
        "    target_col = 'TOTAL_OFFERED_CALL_VOLUME'\n",
        "    model_data_encoded_scaled = model_data_encoded.copy()\n",
        "    scaler = MinMaxScaler()\n",
        "    model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
        "        model_data_encoded_scaled[['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']])\n",
        "\n",
        "    def create_sequences(data, seq_length, horizon):\n",
        "        X= []\n",
        "        for i in range(len(data) - seq_length - horizon + 1):\n",
        "            X.append(data[i:i + seq_length])\n",
        "        return np.array(X)\n",
        "\n",
        "    X_train= create_sequences(model_data_encoded_scaled, 360, 180)\n",
        "    model = tf.keras.models.load_model(r\"/content/Agentic_AI_LSTM_v1.h5\")\n",
        "    predictions = model.predict(X_train)\n",
        "    predictions_rescaled = scaler.data_min_[0] + predictions * (scaler.data_max_[0] - scaler.data_min_[0])\n",
        "    predictions_rescaled = predictions_rescaled[0]\n",
        "    start_date = model_data_encoded.index[-1] + pd.Timedelta(days=1)\n",
        "    date_range = pd.date_range(start=start_date, periods=180, freq='D')\n",
        "    forecast_df = pd.DataFrame({'Date':date_range, 'Forecast':predictions_rescaled})\n",
        "    return forecast_df\n",
        "\n",
        "@tool\n",
        "def Last_week_Mape(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Calculates the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes\n",
        "    for the last 7 days (after forecasting 180 days using data excluding the final 14 days).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing date, forecast, actual call volume, and calculated MAPE\n",
        "                      for the overlapping 7-day period.\n",
        "    \"\"\"\n",
        "    global holidays_df,model_data,forecast_last_week_mape\n",
        "    holidays_df = pd.read_csv(r\"/content/Holiday.csv\")\n",
        "    model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")\n",
        "    model_data = model_data.iloc[:-7]\n",
        "    holidays_df['Date'] = pd.to_datetime(holidays_df['Date'],dayfirst=True)\n",
        "    model_data = pd.merge(model_data, holidays_df[['Date', 'Holiday']],\n",
        "                          left_on='REPORT_DT', right_on='Date', how='left')\n",
        "    model_data.drop(columns=['Date'], inplace=True)\n",
        "    model_data['Holiday'] = model_data['Holiday'].fillna('No Holiday')\n",
        "    model_data.sort_values(by='REPORT_DT').reset_index()\n",
        "    model_data.set_index('REPORT_DT', inplace=True)\n",
        "    # model_data = model_data.drop(columns=['index'], axis = 1)\n",
        "    # Ensure that columns are numeric\n",
        "    model_data['DAY_OF_WEEK'] = model_data.index.dayofweek\n",
        "    model_data['DAY_OF_MONTH'] = pd.to_numeric(model_data['DAY_OF_MONTH'], errors='coerce')\n",
        "    model_data['MONTH'] = pd.to_numeric(model_data['MONTH'], errors='coerce')\n",
        "    model_data['QUARTER'] = pd.to_numeric(model_data['QUARTER'], errors='coerce')\n",
        "    # Encode DAY_OF_WEEK (1 to 7)\n",
        "    model_data['DAY_OF_WEEK_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "    model_data['DAY_OF_WEEK_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "    # Encode DAY_OF_MONTH (1 to 31)\n",
        "    model_data['DAY_OF_MONTH_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "    model_data['DAY_OF_MONTH_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "    # Encode MONTH (1 to 12)\n",
        "    model_data['MONTH_SIN'] = np.sin(2 * np.pi * model_data['MONTH'] / 12)\n",
        "    model_data['MONTH_COS'] = np.cos(2 * np.pi * model_data['MONTH'] / 12)\n",
        "    # Encode QUARTER (1 to 4)\n",
        "    model_data['QUARTER_SIN'] = np.sin(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "    model_data['QUARTER_COS'] = np.cos(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "    # Encode extra\n",
        "    model_data['is_sunday'] = (model_data.index.dayofweek == 6).astype(int)\n",
        "    model_data['is_monday'] = (model_data.index.dayofweek == 0).astype(int)\n",
        "    model_data['is_weekend'] = (model_data.index.dayofweek >= 5).astype(int)\n",
        "    encoding = model_data.groupby('Holiday')['TOTAL_OFFERED_CALL_VOLUME'].mean().to_dict()\n",
        "    model_data['HOLIDAY_ENCODED'] = model_data['Holiday'].map(encoding)\n",
        "    default_value = model_data['TOTAL_OFFERED_CALL_VOLUME'].mean()\n",
        "    model_data['HOLIDAY_ENCODED'] = model_data['HOLIDAY_ENCODED'].fillna(default_value)\n",
        "    model_data_encoded = model_data.drop(columns=['DAY_OF_WEEK','DAY_OF_MONTH',\"YEAR\",\"QUARTER\",\"Holiday\",\"MONTH\"])\n",
        "        # Define input features and target\n",
        "    feature_cols = ['DAY_OF_WEEK_SIN', 'DAY_OF_WEEK_COS',\n",
        "                    'DAY_OF_MONTH_SIN', 'DAY_OF_MONTH_COS', 'MONTH_SIN', 'MONTH_COS',\n",
        "                    'QUARTER_SIN', 'QUARTER_COS', 'HOLIDAY_ENCODED']\n",
        "    target_col = 'TOTAL_OFFERED_CALL_VOLUME'\n",
        "    model_data_encoded_scaled = model_data_encoded.copy()\n",
        "    scaler = MinMaxScaler()\n",
        "    model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
        "        model_data_encoded_scaled[['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']])\n",
        "\n",
        "    def create_sequences(data, seq_length, horizon):\n",
        "        X= []\n",
        "        for i in range(len(data) - seq_length - horizon + 1):\n",
        "            X.append(data[i:i + seq_length])\n",
        "        return np.array(X)\n",
        "    X_train= create_sequences(model_data_encoded_scaled, 360, 180)\n",
        "    model = tf.keras.models.load_model(r\"/content/Agentic_AI_LSTM_v1.h5\")\n",
        "    predictions = model.predict(X_train)\n",
        "    predictions_rescaled = scaler.data_min_[0] + predictions * (scaler.data_max_[0] - scaler.data_min_[0])\n",
        "    predictions_rescaled = predictions_rescaled[0]\n",
        "    start_date = model_data_encoded.index[-1] + pd.Timedelta(days=1)\n",
        "    date_range = pd.date_range(start=start_date, periods=180, freq='D')\n",
        "    forecast_df = pd.DataFrame({'Date':date_range, 'Forecast':predictions_rescaled})\n",
        "    model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")\n",
        "    model_data = model_data.reset_index()\n",
        "    model_data.rename(columns={'REPORT_DT':'Date'},inplace=True)\n",
        "    forecast_last_week = forecast_df.merge(model_data[['Date','TOTAL_OFFERED_CALL_VOLUME']],on=['Date'],how='inner')\n",
        "    forecast_last_week['MAPE'] = (abs(forecast_last_week['TOTAL_OFFERED_CALL_VOLUME'] - forecast_last_week['Forecast'])\n",
        "                                  /forecast_last_week['TOTAL_OFFERED_CALL_VOLUME'])*100\n",
        "    forecast_last_week_mape = forecast_last_week['MAPE'].mean()\n",
        "\n",
        "    return forecast_last_week_mape\n",
        "\n",
        "tools = [preprocess, LSTM_Prediction,Last_week_Mape]\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    project=\"steady-bonsai-467007-g0\",\n",
        "    location=\"us-central1\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    credentials=credentials\n",
        ")\n",
        "bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"agent\", agent_node)\n",
        "graph.set_entry_point(\"agent\")\n",
        "\n",
        "runnable = graph.compile()\n",
        "prompt = \"Preprocesses the dataframe with  'model_data' and Predicts future call volumes using a pre-trained LSTM model with 'model_data_encoded' \"\n",
        "output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "prompt2 = \"Calculate the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes for the last 7 days with 'model_data' \"\n",
        "output2 = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt2}]})\n",
        "\n",
        "print(\"\\nFinal output from agent:\\n\")\n",
        "for msg in output[\"messages\"]:\n",
        "    if hasattr(msg, \"name\"):\n",
        "        print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "\n",
        "for msg in output2[\"messages\"]:\n",
        "    if hasattr(msg, \"name\"):\n",
        "        print(f\"[TOOL: {msg.name}] {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM6Sc7xotnsA",
        "outputId": "1634648e-aac9-4974-c445-42ac961ada7e"
      },
      "id": "kM6Sc7xotnsA",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-104-1527735981.py:73: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.84579339 0.56467306 0.03044069 ... 0.3331664  0.54442696 0.41865789]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 448ms/step\n",
            "H1\n",
            "H2\n",
            "H3\n",
            "H4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-104-1527735981.py:150: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.84579339 0.56467306 0.03044069 ... 0.54757476 0.61865074 0.2702461 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 481ms/step\n",
            "H5\n",
            "H6\n",
            "\n",
            "Final output from agent:\n",
            "\n",
            "[TOOL: None] Preprocesses the dataframe with  'model_data' and Predicts future call volumes using a pre-trained LSTM model with 'model_data_encoded' \n",
            "[TOOL: None] \n",
            "[TOOL: preprocess]             TOTAL_OFFERED_CALL_VOLUME  DAY_OF_WEEK_SIN  DAY_OF_WEEK_COS  \\\n",
            "REPORT_DT                                                                 \n",
            "2020-07-01                      32654         0.974928        -0.222521   \n",
            "2020-07-02                      24795         0.433884        -0.900969   \n",
            "2020-07-03                       9860        -0.433884        -0.900969   \n",
            "2020-07-04                      14390        -0.974928        -0.222521   \n",
            "2020-07-05                      30575        -0.781831         0.623490   \n",
            "...                               ...              ...              ...   \n",
            "2025-06-26                      34068         0.433884        -0.900969   \n",
            "2025-06-27                      22737        -0.433884        -0.900969   \n",
            "2025-06-28                      18323        -0.974928        -0.222521   \n",
            "2025-06-29                      24229        -0.781831         0.623490   \n",
            "2025-06-30                      20713         0.000000         1.000000   \n",
            "\n",
            "            DAY_OF_MONTH_SIN  DAY_OF_MONTH_COS     MONTH_SIN  MONTH_COS  \\\n",
            "REPORT_DT                                                                 \n",
            "2020-07-01          0.201299          0.979530 -5.000000e-01  -0.866025   \n",
            "2020-07-02          0.394356          0.918958 -5.000000e-01  -0.866025   \n",
            "2020-07-03          0.571268          0.820763 -5.000000e-01  -0.866025   \n",
            "2020-07-04          0.724793          0.688967 -5.000000e-01  -0.866025   \n",
            "2020-07-05          0.848644          0.528964 -5.000000e-01  -0.866025   \n",
            "...                      ...               ...           ...        ...   \n",
            "2025-06-26         -0.848644          0.528964  1.224647e-16  -1.000000   \n",
            "2025-06-27         -0.724793          0.688967  1.224647e-16  -1.000000   \n",
            "2025-06-28         -0.571268          0.820763  1.224647e-16  -1.000000   \n",
            "2025-06-29         -0.394356          0.918958  1.224647e-16  -1.000000   \n",
            "2025-06-30         -0.201299          0.979530  1.224647e-16  -1.000000   \n",
            "\n",
            "             QUARTER_SIN   QUARTER_COS  is_sunday  is_monday  is_weekend  \\\n",
            "REPORT_DT                                                                  \n",
            "2020-07-01 -1.000000e+00 -1.836970e-16          0          0           0   \n",
            "2020-07-02 -1.000000e+00 -1.836970e-16          0          0           0   \n",
            "2020-07-03 -1.000000e+00 -1.836970e-16          0          0           0   \n",
            "2020-07-04 -1.000000e+00 -1.836970e-16          0          0           1   \n",
            "2020-07-05 -1.000000e+00 -1.836970e-16          1          0           1   \n",
            "...                  ...           ...        ...        ...         ...   \n",
            "2025-06-26  1.224647e-16 -1.000000e+00          0          0           0   \n",
            "2025-06-27  1.224647e-16 -1.000000e+00          0          0           0   \n",
            "2025-06-28  1.224647e-16 -1.000000e+00          0          0           1   \n",
            "2025-06-29  1.224647e-16 -1.000000e+00          1          0           1   \n",
            "2025-06-30  1.224647e-16 -1.000000e+00          0          1           0   \n",
            "\n",
            "            HOLIDAY_ENCODED  \n",
            "REPORT_DT                    \n",
            "2020-07-01     23284.792028  \n",
            "2020-07-02     23284.792028  \n",
            "2020-07-03     23284.792028  \n",
            "2020-07-04     23211.000000  \n",
            "2020-07-05     23284.792028  \n",
            "...                     ...  \n",
            "2025-06-26     23284.792028  \n",
            "2025-06-27     23284.792028  \n",
            "2025-06-28     23284.792028  \n",
            "2025-06-29     23284.792028  \n",
            "2025-06-30     23284.792028  \n",
            "\n",
            "[1826 rows x 13 columns]\n",
            "[TOOL: LSTM_Prediction]           Date      Forecast\n",
            "0   2025-07-01  18657.938246\n",
            "1   2025-07-02  19991.647395\n",
            "2   2025-07-03  19417.162908\n",
            "3   2025-07-04  21643.090549\n",
            "4   2025-07-05  13856.495825\n",
            "..         ...           ...\n",
            "175 2025-12-23  23944.465259\n",
            "176 2025-12-24  23508.302619\n",
            "177 2025-12-25  20888.359085\n",
            "178 2025-12-26  23039.292060\n",
            "179 2025-12-27  19118.620600\n",
            "\n",
            "[180 rows x 2 columns]\n",
            "[TOOL: None] The `preprocess` function has been executed on the `model_data` dataframe, and the resulting `model_data_encoded` dataframe has been used to predict future call volumes using the `LSTM_Prediction` function. The first 180 days of forecasted call volumes are shown in the table.\n",
            "[TOOL: None] Calculate the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes for the last 7 days with 'model_data' \n",
            "[TOOL: None] \n",
            "[TOOL: Last_week_Mape] 28.213471296479355\n",
            "[TOOL: None] The Mean Absolute Percentage Error (MAPE) for the last 7 days is 28.21%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m7_a8E_Xopl9",
        "outputId": "eddbf2af-e464-4650-b226-c50563ef53f3"
      },
      "id": "m7_a8E_Xopl9",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date      Forecast\n",
              "0   2025-07-01  18657.938246\n",
              "1   2025-07-02  19991.647395\n",
              "2   2025-07-03  19417.162908\n",
              "3   2025-07-04  21643.090549\n",
              "4   2025-07-05  13856.495825\n",
              "..         ...           ...\n",
              "175 2025-12-23  23944.465259\n",
              "176 2025-12-24  23508.302619\n",
              "177 2025-12-25  20888.359085\n",
              "178 2025-12-26  23039.292060\n",
              "179 2025-12-27  19118.620600\n",
              "\n",
              "[180 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ede1e4f-8542-4120-ae72-1532092d592d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Forecast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-07-01</td>\n",
              "      <td>18657.938246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-07-02</td>\n",
              "      <td>19991.647395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-07-03</td>\n",
              "      <td>19417.162908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-07-04</td>\n",
              "      <td>21643.090549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-07-05</td>\n",
              "      <td>13856.495825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>2025-12-23</td>\n",
              "      <td>23944.465259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>2025-12-24</td>\n",
              "      <td>23508.302619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>2025-12-25</td>\n",
              "      <td>20888.359085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>2025-12-26</td>\n",
              "      <td>23039.292060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>2025-12-27</td>\n",
              "      <td>19118.620600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ede1e4f-8542-4120-ae72-1532092d592d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ede1e4f-8542-4120-ae72-1532092d592d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ede1e4f-8542-4120-ae72-1532092d592d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2b5a9fe0-8875-45c7-a4e5-71306f1ba509\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b5a9fe0-8875-45c7-a4e5-71306f1ba509')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2b5a9fe0-8875-45c7-a4e5-71306f1ba509 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b620fe52-7642-4014-a92f-67ae883a596f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('forecast_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b620fe52-7642-4014-a92f-67ae883a596f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('forecast_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "forecast_df",
              "summary": "{\n  \"name\": \"forecast_df\",\n  \"rows\": 180,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-07-01 00:00:00\",\n        \"max\": \"2025-12-27 00:00:00\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          \"2025-07-20 00:00:00\",\n          \"2025-08-12 00:00:00\",\n          \"2025-12-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Forecast\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6201.755692547841,\n        \"min\": 9704.550055503845,\n        \"max\": 38606.296174526215,\n        \"num_unique_values\": 180,\n        \"samples\": [\n          29617.733900547028,\n          24145.115337133408,\n          33119.320706129074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FESTIV"
      ],
      "metadata": {
        "id": "Tz2cExl-6GSL"
      },
      "id": "Tz2cExl-6GSL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def identify_holidays(input: str) -> str:\n",
        "\n",
        "  \"\"\"\n",
        "  Identify holiday dates in the forecast dataset and compare forecasted call volumes with the average actuals\n",
        "  for the same weekday over the past 3 weeks to estimate the forecasted holiday impact.\n",
        "\n",
        "  Returns:\n",
        "      pd.DataFrame: A DataFrame showing:\n",
        "          - Holiday date\n",
        "          - Holiday name\n",
        "          - Day of the week\n",
        "          - 3-week average actuals for the same weekday\n",
        "          - Forecasted volume\n",
        "          - Percentage difference indicating the forecasted impact\n",
        "  \"\"\"\n",
        "  global forecast_df, model_data, holidays_df,forecast_holiday_impact\n",
        "  df_actual = model_data.copy()\n",
        "  df_holidays = holidays_df.copy()\n",
        "  df_forecast = forecast_df.copy()\n",
        "  df_actual.rename(columns={'REPORT_DT':'Date','TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "  df_forecast['Date'] = pd.to_datetime(df_forecast['Date'])\n",
        "  df_actual['Date'] = pd.to_datetime(df_actual['Date'])\n",
        "  df_holidays['Date'] = pd.to_datetime(df_holidays['Date'],dayfirst=True)\n",
        "  df_forecast['day_of_week'] = pd.to_datetime(df_forecast['Date']).dt.day_name()\n",
        "  df_actual['day_of_week'] = pd.to_datetime(df_actual['Date']).dt.day_name()\n",
        "  holiday_forecast = df_forecast.merge(df_holidays, left_on = \"Date\", right_on = \"Date\", how = \"inner\")\n",
        "  holiday_forecast = holiday_forecast[[\"Date\",\"Holiday\",\"day_of_week\",\"Forecast\"]]\n",
        "  holiday_forecast.rename(columns={\"day_of_week\":\"Day of Week\"}, inplace = True)\n",
        "  dow_averages = []\n",
        "  for date, dow in zip(holiday_forecast['Date'], holiday_forecast['Day of Week']):\n",
        "      start_date = date - pd.Timedelta(weeks=3)\n",
        "      filtered = df_actual[(df_actual['Date'] < date) & (df_actual['Date'] >= start_date)]\n",
        "      avg = filtered[filtered['day_of_week'] == dow]['Call Volume'].mean()\n",
        "      dow_averages.append(avg)\n",
        "  holiday_forecast['dow_avg_3w'] = dow_averages\n",
        "  holiday_forecast['Impact_Captured'] = round(\n",
        "      (holiday_forecast['Forecast'] - holiday_forecast['dow_avg_3w']) /\n",
        "      holiday_forecast['dow_avg_3w'] * 100, 2\n",
        "  )\n",
        "  forecast_holiday_impact = holiday_forecast.copy()\n",
        "  return forecast_holiday_impact\n",
        "\n",
        "@tool\n",
        "def holiday_impact(input: str) -> str:\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate the *actual* impact of holidays on call volume by comparing actuals to a 3-week weekday average.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A summarized DataFrame grouped by holiday, showing:\n",
        "            - Holiday name\n",
        "            - Mean actual call volume on the holiday\n",
        "            - Mean percentage difference compared to normal same-day-of-week volumes (Actual Impact)\n",
        "    \"\"\"\n",
        "    global model_data, holidays_df,historic_holiday_impact\n",
        "    df_actuals = model_data.copy()\n",
        "    df_holidays = holidays_df.copy()\n",
        "    df_actuals.rename(columns={'REPORT_DT':'Date','TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "    df_forecast = forecast_df.copy()\n",
        "    df_actuals['Date'] = pd.to_datetime(df_actuals['Date'])\n",
        "    df_holidays['Date'] = pd.to_datetime(df_holidays['Date'],dayfirst=True)\n",
        "    merged_df = pd.merge(df_actuals, df_holidays[['Date', \"Holiday\"]], left_on='Date', right_on='Date', how='left')\n",
        "    # Fill NaN values in the 'Holiday' column with 'Normal Day'\n",
        "    merged_df['Holiday'] = merged_df['Holiday'].fillna('Normal Day')\n",
        "    dow_averages = []\n",
        "    for date, dow in zip(merged_df['Date'], merged_df['DAY_OF_WEEK']):\n",
        "        start_date = date - pd.Timedelta(weeks=3)\n",
        "        filtered = merged_df[(merged_df['Date'] < date) & (merged_df['Date'] >= start_date)]\n",
        "        avg = filtered[filtered['DAY_OF_WEEK'] == dow]['Call Volume'].mean()\n",
        "        dow_averages.append(avg)\n",
        "    merged_df['dow_avg_3w'] = dow_averages\n",
        "    merged_df['Actual_Impact'] = round((merged_df['Call Volume']-merged_df['dow_avg_3w'])/merged_df['dow_avg_3w']*100,2)\n",
        "    historic_holiday_impact = merged_df.groupby(\"Holiday\",as_index = False).agg({\"Actual_Impact\":\"mean\",\"Call Volume\":\"mean\"}).reset_index(drop=True)\n",
        "    return historic_holiday_impact\n",
        "\n",
        "@tool\n",
        "def final_adjustment(input: str) -> str:\n",
        "\n",
        "    \"\"\"\n",
        "    Performs a final adjustment on the holiday-forecasted call volumes by incorporating\n",
        "    the difference between actual historical impact and the impact already captured.\n",
        "    \"\"\"\n",
        "    global adjust_df\n",
        "    adjust_df = forecast_holiday_impact.merge(historic_holiday_impact, on=\"Holiday\", how = \"left\")\n",
        "    adjust_df['Impact_Not_Captured'] = adjust_df['Actual_Impact'] - adjust_df['Impact_Captured']\n",
        "    adjust_df['FestiVcast_Adjusted_Forecast'] = np.where(adjust_df['Impact_Not_Captured']>0, adjust_df['Forecast']*(1+(adjust_df['Impact_Not_Captured'])/100), adjust_df['Forecast'])\n",
        "    return adjust_df\n",
        "\n",
        "\n",
        "tools = [final_adjustment, holiday_impact,identify_holidays]\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    project=\"steady-bonsai-467007-g0\",\n",
        "    location=\"us-central1\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    credentials=credentials\n",
        ")\n",
        "bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"agent\", agent_node)\n",
        "graph.set_entry_point(\"agent\")\n",
        "\n",
        "runnable = graph.compile()\n",
        "prompt = \"identify the holidays present in 'forecast_df' and thenEvaluate the actual impact of holidays on call volume and finally  Performs a final adjustment on the holiday-forecasted call volumes\"\n",
        "output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "print(\"\\nFinal output from agent:\\n\")\n",
        "for msg in output[\"messages\"]:\n",
        "    if hasattr(msg, \"name\"):\n",
        "        print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edchj5RJ3wOZ",
        "outputId": "0deecbcb-20b3-4e4c-ed7e-93c27717cded"
      },
      "id": "edchj5RJ3wOZ",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final output from agent:\n",
            "\n",
            "[TOOL: None] identify the holidays present in 'forecast_df' and thenEvaluate the actual impact of holidays on call volume and finally  Performs a final adjustment on the holiday-forecasted call volumes\n",
            "[TOOL: None] \n",
            "[TOOL: identify_holidays]         Date           Holiday Day of Week      Forecast    dow_avg_3w  \\\n",
            "0 2025-07-04  Independence Day      Friday  21643.090549  27750.333333   \n",
            "1 2025-09-01         Labor Day      Monday  16431.670677           NaN   \n",
            "2 2025-10-13      Columbus Day      Monday  27283.933681           NaN   \n",
            "3 2025-10-31         Halloween      Friday  28916.843330           NaN   \n",
            "4 2025-11-11      Veterans Day     Tuesday  34469.892887           NaN   \n",
            "5 2025-11-27  Thanksgiving Day    Thursday  30024.826141           NaN   \n",
            "6 2025-11-28      Black Friday      Friday  27103.125992           NaN   \n",
            "7 2025-12-01      Cyber Monday      Monday  33119.320706           NaN   \n",
            "8 2025-12-24     Christmas Eve   Wednesday  23508.302619           NaN   \n",
            "9 2025-12-25     Christmas Day    Thursday  20888.359085           NaN   \n",
            "\n",
            "   Impact_Captured  \n",
            "0           -22.01  \n",
            "1              NaN  \n",
            "2              NaN  \n",
            "3              NaN  \n",
            "4              NaN  \n",
            "5              NaN  \n",
            "6              NaN  \n",
            "7              NaN  \n",
            "8              NaN  \n",
            "9              NaN  \n",
            "[TOOL: holiday_impact]                        Holiday  Actual_Impact   Call Volume\n",
            "0                 Black Friday     -28.168000  18145.000000\n",
            "1                Christmas Day      28.028000  28821.000000\n",
            "2                Christmas Eve     -23.530000  16877.600000\n",
            "3                 Columbus Day       2.870000  19896.800000\n",
            "4                 Cyber Monday      32.690000  28951.800000\n",
            "5                       Easter      15.014000  27125.600000\n",
            "6                    Halloween      -3.562000  23450.400000\n",
            "7             Independence Day      26.630000  23211.000000\n",
            "8                   Juneteenth       4.512000  21551.600000\n",
            "9                    Labor Day     -21.578000  17450.200000\n",
            "10  Martin Luther King Jr. Day      22.532000  28489.200000\n",
            "11                Memorial Day       2.670000  23497.000000\n",
            "12              New Year's Day      -5.304000  23193.800000\n",
            "13              New Year's Eve       7.382000  20729.400000\n",
            "14                  Normal Day       4.952162  23284.792028\n",
            "15             President's Day     -15.742000  21517.800000\n",
            "16           St. Patrick's Day      27.028000  21237.000000\n",
            "17            Thanksgiving Day      13.412000  24315.800000\n",
            "18             Valentine's Day     -15.342000  18520.800000\n",
            "19                Veterans Day      22.126000  26574.800000\n",
            "[TOOL: final_adjustment]         Date           Holiday Day of Week      Forecast    dow_avg_3w  \\\n",
            "0 2025-07-04  Independence Day      Friday  21643.090549  27750.333333   \n",
            "1 2025-09-01         Labor Day      Monday  16431.670677           NaN   \n",
            "2 2025-10-13      Columbus Day      Monday  27283.933681           NaN   \n",
            "3 2025-10-31         Halloween      Friday  28916.843330           NaN   \n",
            "4 2025-11-11      Veterans Day     Tuesday  34469.892887           NaN   \n",
            "5 2025-11-27  Thanksgiving Day    Thursday  30024.826141           NaN   \n",
            "6 2025-11-28      Black Friday      Friday  27103.125992           NaN   \n",
            "7 2025-12-01      Cyber Monday      Monday  33119.320706           NaN   \n",
            "8 2025-12-24     Christmas Eve   Wednesday  23508.302619           NaN   \n",
            "9 2025-12-25     Christmas Day    Thursday  20888.359085           NaN   \n",
            "\n",
            "   Impact_Captured  Actual_Impact  Call Volume  Impact_Not_Captured  \\\n",
            "0           -22.01         26.630      23211.0                48.64   \n",
            "1              NaN        -21.578      17450.2                  NaN   \n",
            "2              NaN          2.870      19896.8                  NaN   \n",
            "3              NaN         -3.562      23450.4                  NaN   \n",
            "4              NaN         22.126      26574.8                  NaN   \n",
            "5              NaN         13.412      24315.8                  NaN   \n",
            "6              NaN        -28.168      18145.0                  NaN   \n",
            "7              NaN         32.690      28951.8                  NaN   \n",
            "8              NaN        -23.530      16877.6                  NaN   \n",
            "9              NaN         28.028      28821.0                  NaN   \n",
            "\n",
            "   FestiVcast_Adjusted_Forecast  \n",
            "0                  32170.289792  \n",
            "1                  16431.670677  \n",
            "2                  27283.933681  \n",
            "3                  28916.843330  \n",
            "4                  34469.892887  \n",
            "5                  30024.826141  \n",
            "6                  27103.125992  \n",
            "7                  33119.320706  \n",
            "8                  23508.302619  \n",
            "9                  20888.359085  \n",
            "[TOOL: None] Following are the holidays present in the forecast data and their corresponding forecasted impact:\n",
            "\n",
            "| Date | Holiday | Day of Week | Forecast | 3-week Avg Actuals | Impact Captured (%) |\n",
            "|---|---|---|---|---|---|\n",
            "| 2025-07-04 | Independence Day | Friday | 21643.09 | 27750.33 | -22.01 |\n",
            "| 2025-09-01 | Labor Day | Monday | 16431.67 | NaN | NaN |\n",
            "| 2025-10-13 | Columbus Day | Monday | 27283.93 | NaN | NaN |\n",
            "| 2025-10-31 | Halloween | Friday | 28916.84 | NaN | NaN |\n",
            "| 2025-11-11 | Veterans Day | Tuesday | 34469.89 | NaN | NaN |\n",
            "| 2025-11-27 | Thanksgiving Day | Thursday | 30024.83 | NaN | NaN |\n",
            "| 2025-11-28 | Black Friday | Friday | 27103.13 | NaN | NaN |\n",
            "| 2025-12-01 | Cyber Monday | Monday | 33119.32 | NaN | NaN |\n",
            "| 2025-12-24 | Christmas Eve | Wednesday | 23508.30 | NaN | NaN |\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seaso"
      ],
      "metadata": {
        "id": "nhy6aLNZ6EVD"
      },
      "id": "nhy6aLNZ6EVD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_historical_periods_dynamic_actual(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the same date range in previous years from a DataFrame, dynamically determining available years.\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are years and values are DataFrames\n",
        "              containing the corresponding period. Returns an empty dictionary if there are issues.\n",
        "    \"\"\"\n",
        "    global forecast_df, model_data,final_last_28_days\n",
        "    df = model_data.iloc[-28:].copy()\n",
        "    df_history =  model_data.copy()\n",
        "    date_column='Date'\n",
        "    start_date=None\n",
        "    end_date=None\n",
        "\n",
        "    df_history.rename(columns={'REPORT DT':'Date', 'TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "    # Determine start and end dates if not provided\n",
        "    if start_date is None or end_date is None:\n",
        "        end_date = df[date_column].max()\n",
        "        start_date = df[date_column].min()\n",
        "    else:\n",
        "        start_date = pd.to_datetime(start_date)\n",
        "        end_date = pd.to_datetime(end_date)\n",
        "    # Calculate the date range\n",
        "    date_range = end_date - start_date\n",
        "    if date_range.days < 0:\n",
        "        print(\"Error: End date is earlier than start date.\")\n",
        "    historical_periods = {}\n",
        "    current_year = end_date.year # Use the end date year as the \"current\" year\n",
        "    available_years = sorted(df_history[date_column].dt.year.unique(), reverse=True)\n",
        "    # Iterate through available years *excluding* the current year\n",
        "    for year in available_years:\n",
        "        if year == current_year:\n",
        "            continue #skip current year\n",
        "        # Calculate the start and end dates for the current year\n",
        "        year_start_date = pd.to_datetime(f'{year}-{start_date.month}-{start_date.day}')\n",
        "        year_end_date = pd.to_datetime(f'{year}-{end_date.month}-{end_date.day}')\n",
        "        # Filter the Dataframe for the current year period\n",
        "        year_df = df_history[(df_history[date_column] >= year_start_date) & (df_history[date_column] <= year_end_date)].copy()\n",
        "        if not year_df.empty:\n",
        "            historical_periods[year] = year_df\n",
        "        else:\n",
        "            print(f'No data found for {year}.')\n",
        "    historical_periods_yearly = pd.DataFrame()\n",
        "    last_28days_dict = historical_periods.copy()\n",
        "    counter = 0\n",
        "    final_last_28_days = pd.DataFrame()\n",
        "    for i in last_28days_dict.keys():\n",
        "        if counter<3:\n",
        "            globals()[f\"last_28days_{i}\"] = last_28days_dict[i]\n",
        "        else:\n",
        "            break\n",
        "        final_last_28_days = pd.concat([final_last_28_days,globals()[f\"last_28days_{i}\"]], ignore_index = True)\n",
        "        final_last_28_days['Year'] = final_last_28_days['Date'].dt.year\n",
        "    return final_last_28_days\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_historical_periods_dynamic_forecast(input: str) -> str:\n",
        "\n",
        "    \"\"\"\n",
        "    Forecast is Extracted for the same date range from forecast dataframe, dynamically determining available years.\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are years and values are DataFrames\n",
        "              containing the corresponding period. Returns an empty dictionary if there are issues.\n",
        "    \"\"\"\n",
        "    global forecast_df, model_data,final_next_28_days\n",
        "    df = forecast_df.copy()\n",
        "    df_history =  model_data.copy()\n",
        "    date_column='Date'\n",
        "    start_date=None\n",
        "    end_date=None\n",
        "\n",
        "    df_history.rename(columns={'REPORT_DT': 'Date', 'TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "    # Determine start and end dates if not provided\n",
        "    if start_date is None or end_date is None:\n",
        "        end_date = df[date_column].max()\n",
        "        start_date = df[date_column].min()\n",
        "    else:\n",
        "        start_date = pd.to_datetime(start_date)\n",
        "        end_date = pd.to_datetime(end_date)\n",
        "    # Calculate the date range\n",
        "    date_range = end_date - start_date\n",
        "    if date_range.days < 0:\n",
        "        print(\"Error: End date is earlier than start date.\")\n",
        "    historical_periods = {}\n",
        "    current_year = end_date.year # Use the end_date year as the \"current\" year\n",
        "    available_years = sorted(df_history[date_column].dt.year.unique(), reverse=True)\n",
        "    # Iterate through available years excluding the \"current\" year\n",
        "    for year in available_years:\n",
        "        if year == current_year:\n",
        "            continue #skip current year\n",
        "        year_start_date = pd.to_datetime(f'{year}-{start_date.month}-{start_date.day}')\n",
        "        year_end_date = pd.to_datetime(f'{year}-{end_date.month}-{end_date.day}')\n",
        "        year_df = df_history[(df_history[date_column] >= year_start_date) & (df_history[date_column] <= year_end_date)].copy()\n",
        "        if not year_df.empty:\n",
        "            historical_periods[year] = year_df\n",
        "    else:\n",
        "        historical_periods[year] = pd.DataFrame()\n",
        "    next_28days_dict = historical_periods.copy()\n",
        "    counter = 0\n",
        "    # Initialize an empty DataFrame\n",
        "    final_next_28_days = pd.DataFrame()\n",
        "    for i in next_28days_dict.keys():\n",
        "        if counter<3:\n",
        "            globals()[f\"next_28days_{i}\"] = next_28days_dict[i]\n",
        "            counter+=1\n",
        "        else:\n",
        "            break\n",
        "        final_next_28_days = pd.concat([final_next_28_days,globals()[f\"next_28days_{i}\"]], ignore_index = True)\n",
        "        final_next_28_days['Year'] = final_next_28_days['Date'].dt.year\n",
        "    return final_next_28_days\n",
        "\n",
        "@tool\n",
        "def Final_adjustment_Seso(input: str) -> str:\n",
        "  \"\"\"\n",
        "    Applies a last-mile seasonal adjustment to the forecasted call volumes based on\n",
        "    day-of-week (DOW) trends observed in the last 28 days vs the upcoming 28 days.\n",
        "  \"\"\"\n",
        "  global forecast_df, model_data,final_next_28_days,forecast_merged,final_last_28_days\n",
        "  final_next_28_dow_avg = final_next_28_days.groupby([\"Year\",\"DAY_OF_WEEK\"], as_index = False).agg({\"Call Volume\":\"mean\"})\n",
        "  final_next_28_dow_avg = final_next_28_dow_avg.rename(columns = {'Call Volume':'actual_offered_next'})\n",
        "  final_last_28_dow_avg = final_last_28_days.groupby([\"Year\",\"DAY_OF_WEEK\"], as_index = False).agg({\"Call Volume\":\"mean\"})\n",
        "  final_last_28_dow_avg = final_last_28_dow_avg.rename(columns = {'Call Volume':'actual_offered_last'})\n",
        "  final_seasonal_comparison_df = final_next_28_dow_avg.merge(final_last_28_dow_avg, on = [\"Year\",\"DAY_OF_WEEK\"], how = \"inner\")\n",
        "  final_seasonal_comparison_df[\"Seasonal_Factor\"] = (final_seasonal_comparison_df[\"actual_offered_next\"]/ final_seasonal_comparison_df[\"actual_offered_last\"])\n",
        "  final_seasonality_dim = final_seasonal_comparison_df.groupby([\"DAY_OF_WEEK\"], as_index = False).agg({\"Seasonal_Factor\":\"mean\"})\n",
        "\n",
        "  forecast_df['DAY_OF_WEEK'] = pd.to_datetime(forecast_df['Date']).dt.day_name()\n",
        "\n",
        "  forecast_merged = forecast_df.merge(final_seasonality_dim,on=['DAY_OF_WEEK'],how='inner')\n",
        "  forecast_merged['LM_Seasonal_Adjustment'] = forecast_merged['Forecast'] * forecast_merged['Seasonal_Factor']\n",
        "  forecast_merged = forecast_merged[['Date','DAY_OF_WEEK','Forecast','Seasonal_Factor','LM_Seasonal_Adjustment']]\n",
        "  return forecast_merged\n",
        "\n",
        "\n",
        "tools = [Final_adjustment_Seso, get_historical_periods_dynamic_forecast,get_historical_periods_dynamic_actual]\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    project=\"steady-bonsai-467007-g0\",\n",
        "    location=\"us-central1\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    credentials=credentials\n",
        ")\n",
        "bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"agent\", agent_node)\n",
        "graph.set_entry_point(\"agent\")\n",
        "\n",
        "runnable = graph.compile()\n",
        "prompt = \"extract the same date range in previous years from 'model_data' and also  Extract for the same date range from forecast dataframe 'forecast_df' and finally Apply a last-mile seasonal adjustment to the forecasted call volumes \"\n",
        "output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "print(\"\\nFinal output from agent:\\n\")\n",
        "for msg in output[\"messages\"]:\n",
        "    if hasattr(msg, \"name\"):\n",
        "        print(f\"[TOOL: {msg.name}] {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq-KpjkJ7ZgQ",
        "outputId": "dd62815b-e549-47b1-8364-1dcaaec0e1ea"
      },
      "id": "uq-KpjkJ7ZgQ",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data found for 2020.\n",
            "\n",
            "Final output from agent:\n",
            "\n",
            "[TOOL: None] extract the same date range in previous years from 'model_data' and also  Extract for the same date range from forecast dataframe 'forecast_df' and finally Apply a last-mile seasonal adjustment to the forecasted call volumes \n",
            "[TOOL: None] \n",
            "[TOOL: get_historical_periods_dynamic_actual]      index       Date  Call Volume DAY_OF_WEEK  DAY_OF_MONTH  MONTH  QUARTER  \\\n",
            "0     1433 2024-06-03        33777      Monday             3      6        2   \n",
            "1     1434 2024-06-04        28891     Tuesday             4      6        2   \n",
            "2     1435 2024-06-05        15456   Wednesday             5      6        2   \n",
            "3     1436 2024-06-06        13212    Thursday             6      6        2   \n",
            "4     1437 2024-06-07        22224      Friday             7      6        2   \n",
            "..     ...        ...          ...         ...           ...    ...      ...   \n",
            "107    360 2021-06-26        29817    Saturday            26      6        2   \n",
            "108    361 2021-06-27        20969      Sunday            27      6        2   \n",
            "109    362 2021-06-28        11869      Monday            28      6        2   \n",
            "110    363 2021-06-29        36810     Tuesday            29      6        2   \n",
            "111    364 2021-06-30        26340   Wednesday            30      6        2   \n",
            "\n",
            "     YEAR  Year  \n",
            "0    2024  2024  \n",
            "1    2024  2024  \n",
            "2    2024  2024  \n",
            "3    2024  2024  \n",
            "4    2024  2024  \n",
            "..    ...   ...  \n",
            "107  2021  2021  \n",
            "108  2021  2021  \n",
            "109  2021  2021  \n",
            "110  2021  2021  \n",
            "111  2021  2021  \n",
            "\n",
            "[112 rows x 9 columns]\n",
            "[TOOL: get_historical_periods_dynamic_forecast]      index       Date  Call Volume DAY_OF_WEEK  DAY_OF_MONTH  MONTH  QUARTER  \\\n",
            "0     1461 2024-07-01        21997      Monday             1      7        3   \n",
            "1     1462 2024-07-02        28956     Tuesday             2      7        3   \n",
            "2     1463 2024-07-03        31359   Wednesday             3      7        3   \n",
            "3     1464 2024-07-04        22472    Thursday             4      7        3   \n",
            "4     1465 2024-07-05        31704      Friday             5      7        3   \n",
            "..     ...        ...          ...         ...           ...    ...      ...   \n",
            "535    905 2022-12-23        32833      Friday            23     12        4   \n",
            "536    906 2022-12-24        13158    Saturday            24     12        4   \n",
            "537    907 2022-12-25        29309      Sunday            25     12        4   \n",
            "538    908 2022-12-26        15970      Monday            26     12        4   \n",
            "539    909 2022-12-27        15938     Tuesday            27     12        4   \n",
            "\n",
            "     YEAR  Year  \n",
            "0    2024  2024  \n",
            "1    2024  2024  \n",
            "2    2024  2024  \n",
            "3    2024  2024  \n",
            "4    2024  2024  \n",
            "..    ...   ...  \n",
            "535  2022  2022  \n",
            "536  2022  2022  \n",
            "537  2022  2022  \n",
            "538  2022  2022  \n",
            "539  2022  2022  \n",
            "\n",
            "[540 rows x 9 columns]\n",
            "[TOOL: None] \n",
            "[TOOL: Final_adjustment_Seso]           Date DAY_OF_WEEK      Forecast  Seasonal_Factor  \\\n",
            "0   2025-07-01     Tuesday  18657.938246         0.930398   \n",
            "1   2025-07-02   Wednesday  19991.647395         0.886288   \n",
            "2   2025-07-03    Thursday  19417.162908         1.219900   \n",
            "3   2025-07-04      Friday  21643.090549         1.138394   \n",
            "4   2025-07-05    Saturday  13856.495825         1.393073   \n",
            "..         ...         ...           ...              ...   \n",
            "175 2025-12-23     Tuesday  23944.465259         0.930398   \n",
            "176 2025-12-24   Wednesday  23508.302619         0.886288   \n",
            "177 2025-12-25    Thursday  20888.359085         1.219900   \n",
            "178 2025-12-26      Friday  23039.292060         1.138394   \n",
            "179 2025-12-27    Saturday  19118.620600         1.393073   \n",
            "\n",
            "     LM_Seasonal_Adjustment  \n",
            "0              17359.315050  \n",
            "1              17718.358044  \n",
            "2              23686.998002  \n",
            "3              24638.354299  \n",
            "4              19303.116799  \n",
            "..                      ...  \n",
            "175            22277.891087  \n",
            "176            20835.127520  \n",
            "177            25481.710292  \n",
            "178            26227.781069  \n",
            "179            26633.643248  \n",
            "\n",
            "[180 rows x 5 columns]\n",
            "[TOOL: None] With the 'model_data,' I have extracted the historical data for the same date range in previous years. Similarly, I have extracted the forecast data for the same date range from the 'forecast_df'. Finally, I have applied a last-mile seasonal adjustment to the forecasted call volumes. Here is the final adjusted forecast:\n",
            "\n",
            "```\n",
            "          Date DAY_OF_WEEK      Forecast  Seasonal_Factor  \\\n",
            "0   2025-07-01     Tuesday  18657.938246         0.930398\n",
            "1   2025-07-02   Wednesday  19991.647395         0.886288\n",
            "2   2025-07-03    Thursday  19417.162908         1.219900\n",
            "3   2025-07-04      Friday  21643.090549         1.138394\n",
            "4   2025-07-05    Saturday  13856.495825         1.393073\n",
            "..         ...         ...           ...              ...\n",
            "175 2025-12-23     Tuesday  23944.465259         0.930398\n",
            "176 2025-12-24   Wednesday  23508.302619         0.886288\n",
            "177 2025-12-25    Thursday  20888.359085         1.219900\n",
            "178 2025-12-26      Friday  23039.292060         1.138394\n",
            "179 2025-12-27    Saturday  19118.620600         1.393073\n",
            "\n",
            "     LM_Seasonal_Adjustment\n",
            "0              17359.315050\n",
            "1              17718.358044\n",
            "2              23686.998002\n",
            "3              24638.354299\n",
            "4              19303.116799\n",
            "..                      ...\n",
            "175            22277.891087\n",
            "176            20835.1275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Dict, Any\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Agentic_AI(BaseModel):\n",
        "    Corecast: Optional[Dict[str, Any]] = None\n",
        "    FestivCast: Optional[Dict[str, Any]] = None\n",
        "    SesoCast: Optional[Dict[str, Any]] = None\n",
        "\n",
        "###########################################################################################################################\n",
        "#####################################...............CORECAST..............#################################################\n",
        "###########################################################################################################################\n",
        "def Corecast(state:Agentic_AI ):\n",
        "  @tool\n",
        "  def preprocess(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Preprocess the call volume dataset for modeling.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: Preprocessed and feature-engineered DataFrame ready for LSTM modeling,\n",
        "                        with relevant columns encoded and 'REPORT_DT' set as the index.\n",
        "      \"\"\"\n",
        "      global holidays_df,model_data,model_data_encoded\n",
        "      holidays_df = pd.read_csv(r\"/content/Holiday.csv\")\n",
        "      model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")\n",
        "      holidays_df['Date'] = pd.to_datetime(holidays_df['Date'],dayfirst=True)\n",
        "      model_data = pd.merge(model_data, holidays_df[['Date', 'Holiday']],\n",
        "                            left_on='REPORT_DT', right_on='Date', how='left')\n",
        "      model_data.drop(columns=['Date'], inplace=True)\n",
        "      model_data['Holiday'] = model_data['Holiday'].fillna('No Holiday')\n",
        "      model_data.sort_values(by='REPORT_DT').reset_index()\n",
        "      model_data.set_index('REPORT_DT', inplace=True)\n",
        "      # model_data = model_data.drop(columns=['index'], axis = 1)\n",
        "      # Ensure that columns are numeric\n",
        "      model_data['DAY_OF_WEEK'] = model_data.index.dayofweek\n",
        "      model_data['DAY_OF_MONTH'] = pd.to_numeric(model_data['DAY_OF_MONTH'], errors='coerce')\n",
        "      model_data['MONTH'] = pd.to_numeric(model_data['MONTH'], errors='coerce')\n",
        "      model_data['QUARTER'] = pd.to_numeric(model_data['QUARTER'], errors='coerce')\n",
        "      # Encode DAY_OF_WEEK (1 to 7)\n",
        "      model_data['DAY_OF_WEEK_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      model_data['DAY_OF_WEEK_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      # Encode DAY_OF_MONTH (1 to 31)\n",
        "      model_data['DAY_OF_MONTH_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      model_data['DAY_OF_MONTH_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      # Encode MONTH (1 to 12)\n",
        "      model_data['MONTH_SIN'] = np.sin(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      model_data['MONTH_COS'] = np.cos(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      # Encode QUARTER (1 to 4)\n",
        "      model_data['QUARTER_SIN'] = np.sin(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      model_data['QUARTER_COS'] = np.cos(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      # Encode extra\n",
        "      model_data['is_sunday'] = (model_data.index.dayofweek == 6).astype(int)\n",
        "      model_data['is_monday'] = (model_data.index.dayofweek == 0).astype(int)\n",
        "      model_data['is_weekend'] = (model_data.index.dayofweek >= 5).astype(int)\n",
        "      encoding = model_data.groupby('Holiday')['TOTAL_OFFERED_CALL_VOLUME'].mean().to_dict()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['Holiday'].map(encoding)\n",
        "      default_value = model_data['TOTAL_OFFERED_CALL_VOLUME'].mean()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['HOLIDAY_ENCODED'].fillna(default_value)\n",
        "      model_data_encoded = model_data.drop(columns=['DAY_OF_WEEK','DAY_OF_MONTH',\"YEAR\",\"QUARTER\",\"Holiday\",\"MONTH\"])\n",
        "      return model_data_encoded\n",
        "\n",
        "  @tool\n",
        "  def LSTM_Prediction(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Predicts future call volumes using a pre-trained LSTM model.\n",
        "\n",
        "      This function takes the preprocessed and encoded data, creates input sequences,\n",
        "      loads a trained LSTM model, and returns a 180-day forecast.\n",
        "\n",
        "      Args:\n",
        "          model_data_encoded (pd.DataFrame): The DataFrame with engineered and scaled features,\n",
        "                                            output from the `preprocess` function.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame containing 180 days of future dates and corresponding forecasted\n",
        "                        'TOTAL_OFFERED_CALL_VOLUME' values.\n",
        "      \"\"\"\n",
        "      global forecast_df\n",
        "      # Define input features and target\n",
        "      feature_cols = ['DAY_OF_WEEK_SIN', 'DAY_OF_WEEK_COS',\n",
        "                      'DAY_OF_MONTH_SIN', 'DAY_OF_MONTH_COS', 'MONTH_SIN', 'MONTH_COS',\n",
        "                      'QUARTER_SIN', 'QUARTER_COS', 'HOLIDAY_ENCODED']\n",
        "      target_col = 'TOTAL_OFFERED_CALL_VOLUME'\n",
        "      model_data_encoded_scaled = model_data_encoded.copy()\n",
        "      scaler = MinMaxScaler()\n",
        "      model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
        "          model_data_encoded_scaled[['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']])\n",
        "\n",
        "      def create_sequences(data, seq_length, horizon):\n",
        "          X= []\n",
        "          for i in range(len(data) - seq_length - horizon + 1):\n",
        "              X.append(data[i:i + seq_length])\n",
        "          return np.array(X)\n",
        "\n",
        "      X_train= create_sequences(model_data_encoded_scaled, 360, 180)\n",
        "      model = tf.keras.models.load_model(r\"/content/Agentic_AI_LSTM_v1.h5\")\n",
        "      predictions = model.predict(X_train)\n",
        "      predictions_rescaled = scaler.data_min_[0] + predictions * (scaler.data_max_[0] - scaler.data_min_[0])\n",
        "      predictions_rescaled = predictions_rescaled[0]\n",
        "      start_date = model_data_encoded.index[-1] + pd.Timedelta(days=1)\n",
        "      date_range = pd.date_range(start=start_date, periods=180, freq='D')\n",
        "      forecast_df = pd.DataFrame({'Date':date_range, 'Forecast':predictions_rescaled})\n",
        "      return forecast_df\n",
        "\n",
        "  @tool\n",
        "  def Last_week_Mape(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Calculates the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes\n",
        "      for the last 7 days (after forecasting 180 days using data excluding the final 14 days).\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: DataFrame containing date, forecast, actual call volume, and calculated MAPE\n",
        "                        for the overlapping 7-day period.\n",
        "      \"\"\"\n",
        "      global holidays_df,model_data,forecast_last_week_mape\n",
        "      holidays_df = pd.read_csv(r\"/content/Holiday.csv\")\n",
        "      model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")\n",
        "      model_data = model_data.iloc[:-7]\n",
        "      holidays_df['Date'] = pd.to_datetime(holidays_df['Date'],dayfirst=True)\n",
        "      model_data = pd.merge(model_data, holidays_df[['Date', 'Holiday']],\n",
        "                            left_on='REPORT_DT', right_on='Date', how='left')\n",
        "      model_data.drop(columns=['Date'], inplace=True)\n",
        "      model_data['Holiday'] = model_data['Holiday'].fillna('No Holiday')\n",
        "      model_data.sort_values(by='REPORT_DT').reset_index()\n",
        "      model_data.set_index('REPORT_DT', inplace=True)\n",
        "      # model_data = model_data.drop(columns=['index'], axis = 1)\n",
        "      # Ensure that columns are numeric\n",
        "      model_data['DAY_OF_WEEK'] = model_data.index.dayofweek\n",
        "      model_data['DAY_OF_MONTH'] = pd.to_numeric(model_data['DAY_OF_MONTH'], errors='coerce')\n",
        "      model_data['MONTH'] = pd.to_numeric(model_data['MONTH'], errors='coerce')\n",
        "      model_data['QUARTER'] = pd.to_numeric(model_data['QUARTER'], errors='coerce')\n",
        "      # Encode DAY_OF_WEEK (1 to 7)\n",
        "      model_data['DAY_OF_WEEK_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      model_data['DAY_OF_WEEK_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_WEEK'] / 7)\n",
        "      # Encode DAY_OF_MONTH (1 to 31)\n",
        "      model_data['DAY_OF_MONTH_SIN'] = np.sin(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      model_data['DAY_OF_MONTH_COS'] = np.cos(2 * np.pi * model_data['DAY_OF_MONTH'] / 31)\n",
        "      # Encode MONTH (1 to 12)\n",
        "      model_data['MONTH_SIN'] = np.sin(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      model_data['MONTH_COS'] = np.cos(2 * np.pi * model_data['MONTH'] / 12)\n",
        "      # Encode QUARTER (1 to 4)\n",
        "      model_data['QUARTER_SIN'] = np.sin(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      model_data['QUARTER_COS'] = np.cos(2 * np.pi * model_data['QUARTER'] / 4)\n",
        "      # Encode extra\n",
        "      model_data['is_sunday'] = (model_data.index.dayofweek == 6).astype(int)\n",
        "      model_data['is_monday'] = (model_data.index.dayofweek == 0).astype(int)\n",
        "      model_data['is_weekend'] = (model_data.index.dayofweek >= 5).astype(int)\n",
        "      encoding = model_data.groupby('Holiday')['TOTAL_OFFERED_CALL_VOLUME'].mean().to_dict()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['Holiday'].map(encoding)\n",
        "      default_value = model_data['TOTAL_OFFERED_CALL_VOLUME'].mean()\n",
        "      model_data['HOLIDAY_ENCODED'] = model_data['HOLIDAY_ENCODED'].fillna(default_value)\n",
        "      model_data_encoded = model_data.drop(columns=['DAY_OF_WEEK','DAY_OF_MONTH',\"YEAR\",\"QUARTER\",\"Holiday\",\"MONTH\"])\n",
        "          # Define input features and target\n",
        "      feature_cols = ['DAY_OF_WEEK_SIN', 'DAY_OF_WEEK_COS',\n",
        "                      'DAY_OF_MONTH_SIN', 'DAY_OF_MONTH_COS', 'MONTH_SIN', 'MONTH_COS',\n",
        "                      'QUARTER_SIN', 'QUARTER_COS', 'HOLIDAY_ENCODED']\n",
        "      target_col = 'TOTAL_OFFERED_CALL_VOLUME'\n",
        "      model_data_encoded_scaled = model_data_encoded.copy()\n",
        "      scaler = MinMaxScaler()\n",
        "      model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
        "          model_data_encoded_scaled[['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']])\n",
        "\n",
        "      def create_sequences(data, seq_length, horizon):\n",
        "          X= []\n",
        "          for i in range(len(data) - seq_length - horizon + 1):\n",
        "              X.append(data[i:i + seq_length])\n",
        "          return np.array(X)\n",
        "      X_train= create_sequences(model_data_encoded_scaled, 360, 180)\n",
        "      model = tf.keras.models.load_model(r\"/content/Agentic_AI_LSTM_v1.h5\")\n",
        "      predictions = model.predict(X_train)\n",
        "      predictions_rescaled = scaler.data_min_[0] + predictions * (scaler.data_max_[0] - scaler.data_min_[0])\n",
        "      predictions_rescaled = predictions_rescaled[0]\n",
        "      start_date = model_data_encoded.index[-1] + pd.Timedelta(days=1)\n",
        "      date_range = pd.date_range(start=start_date, periods=180, freq='D')\n",
        "      forecast_df = pd.DataFrame({'Date':date_range, 'Forecast':predictions_rescaled})\n",
        "      model_data = pd.read_excel(r\"/content/Call_Volume_Data_2020_to_2025.xlsx\")\n",
        "      model_data = model_data.reset_index()\n",
        "      model_data.rename(columns={'REPORT_DT':'Date'},inplace=True)\n",
        "      forecast_last_week = forecast_df.merge(model_data[['Date','TOTAL_OFFERED_CALL_VOLUME']],on=['Date'],how='inner')\n",
        "      forecast_last_week['MAPE'] = (abs(forecast_last_week['TOTAL_OFFERED_CALL_VOLUME'] - forecast_last_week['Forecast'])\n",
        "                                    /forecast_last_week['TOTAL_OFFERED_CALL_VOLUME'])*100\n",
        "      forecast_last_week_mape = forecast_last_week['MAPE'].mean()\n",
        "\n",
        "      return forecast_last_week_mape\n",
        "\n",
        "  tools = [preprocess, LSTM_Prediction,Last_week_Mape]\n",
        "  llm = ChatVertexAI(\n",
        "      model=\"gemini-2.5-pro\",\n",
        "      project=\"steady-bonsai-467007-g0\",\n",
        "      location=\"us-central1\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0.7,\n",
        "      credentials=credentials\n",
        "  )\n",
        "  bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "  agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "  graph = StateGraph(AgentState)\n",
        "  graph.add_node(\"agent\", agent_node)\n",
        "  graph.set_entry_point(\"agent\")\n",
        "\n",
        "  runnable = graph.compile()\n",
        "  prompt = \"Preprocesses the dataframe with  'model_data' and Predicts future call volumes using a pre-trained LSTM model with 'model_data_encoded' \"\n",
        "  output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "  prompt2 = \"Calculate the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes for the last 7 days with 'model_data' \"\n",
        "  output2 = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt2}]})\n",
        "\n",
        "  print(\"\\nFinal output from agent:\\n\")\n",
        "  for msg in output[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "\n",
        "  for msg in output2[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "  return None\n",
        "\n",
        "###########################################################################################################################\n",
        "#####################################...............FestivCast..............###############################################\n",
        "###########################################################################################################################\n",
        "def FestivCast(state:Agentic_AI):\n",
        "  @tool\n",
        "  def identify_holidays(input: str) -> str:\n",
        "\n",
        "    \"\"\"\n",
        "    Identify holiday dates in the forecast dataset and compare forecasted call volumes with the average actuals\n",
        "    for the same weekday over the past 3 weeks to estimate the forecasted holiday impact.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame showing:\n",
        "            - Holiday date\n",
        "            - Holiday name\n",
        "            - Day of the week\n",
        "            - 3-week average actuals for the same weekday\n",
        "            - Forecasted volume\n",
        "            - Percentage difference indicating the forecasted impact\n",
        "    \"\"\"\n",
        "    global forecast_df, model_data, holidays_df,forecast_holiday_impact\n",
        "    df_actual = model_data.copy()\n",
        "    df_holidays = holidays_df.copy()\n",
        "    df_forecast = forecast_df.copy()\n",
        "    df_actual.rename(columns={'REPORT_DT':'Date','TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "    df_forecast['Date'] = pd.to_datetime(df_forecast['Date'])\n",
        "    df_actual['Date'] = pd.to_datetime(df_actual['Date'])\n",
        "    df_holidays['Date'] = pd.to_datetime(df_holidays['Date'],dayfirst=True)\n",
        "    df_forecast['day_of_week'] = pd.to_datetime(df_forecast['Date']).dt.day_name()\n",
        "    df_actual['day_of_week'] = pd.to_datetime(df_actual['Date']).dt.day_name()\n",
        "    holiday_forecast = df_forecast.merge(df_holidays, left_on = \"Date\", right_on = \"Date\", how = \"inner\")\n",
        "    holiday_forecast = holiday_forecast[[\"Date\",\"Holiday\",\"day_of_week\",\"Forecast\"]]\n",
        "    holiday_forecast.rename(columns={\"day_of_week\":\"Day of Week\"}, inplace = True)\n",
        "    dow_averages = []\n",
        "    for date, dow in zip(holiday_forecast['Date'], holiday_forecast['Day of Week']):\n",
        "        start_date = date - pd.Timedelta(weeks=3)\n",
        "        filtered = df_actual[(df_actual['Date'] < date) & (df_actual['Date'] >= start_date)]\n",
        "        avg = filtered[filtered['day_of_week'] == dow]['Call Volume'].mean()\n",
        "        dow_averages.append(avg)\n",
        "    holiday_forecast['dow_avg_3w'] = dow_averages\n",
        "    holiday_forecast['Impact_Captured'] = round(\n",
        "        (holiday_forecast['Forecast'] - holiday_forecast['dow_avg_3w']) /\n",
        "        holiday_forecast['dow_avg_3w'] * 100, 2\n",
        "    )\n",
        "    forecast_holiday_impact = holiday_forecast.copy()\n",
        "    return forecast_holiday_impact\n",
        "\n",
        "  @tool\n",
        "  def holiday_impact(input: str) -> str:\n",
        "\n",
        "      \"\"\"\n",
        "      Evaluate the *actual* impact of holidays on call volume by comparing actuals to a 3-week weekday average.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A summarized DataFrame grouped by holiday, showing:\n",
        "              - Holiday name\n",
        "              - Mean actual call volume on the holiday\n",
        "              - Mean percentage difference compared to normal same-day-of-week volumes (Actual Impact)\n",
        "      \"\"\"\n",
        "      global model_data, holidays_df,historic_holiday_impact\n",
        "      df_actuals = model_data.copy()\n",
        "      df_holidays = holidays_df.copy()\n",
        "      df_actuals.rename(columns={'REPORT_DT':'Date','TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "      df_forecast = forecast_df.copy()\n",
        "      df_actuals['Date'] = pd.to_datetime(df_actuals['Date'])\n",
        "      df_holidays['Date'] = pd.to_datetime(df_holidays['Date'],dayfirst=True)\n",
        "      merged_df = pd.merge(df_actuals, df_holidays[['Date', \"Holiday\"]], left_on='Date', right_on='Date', how='left')\n",
        "      # Fill NaN values in the 'Holiday' column with 'Normal Day'\n",
        "      merged_df['Holiday'] = merged_df['Holiday'].fillna('Normal Day')\n",
        "      dow_averages = []\n",
        "      for date, dow in zip(merged_df['Date'], merged_df['DAY_OF_WEEK']):\n",
        "          start_date = date - pd.Timedelta(weeks=3)\n",
        "          filtered = merged_df[(merged_df['Date'] < date) & (merged_df['Date'] >= start_date)]\n",
        "          avg = filtered[filtered['DAY_OF_WEEK'] == dow]['Call Volume'].mean()\n",
        "          dow_averages.append(avg)\n",
        "      merged_df['dow_avg_3w'] = dow_averages\n",
        "      merged_df['Actual_Impact'] = round((merged_df['Call Volume']-merged_df['dow_avg_3w'])/merged_df['dow_avg_3w']*100,2)\n",
        "      historic_holiday_impact = merged_df.groupby(\"Holiday\",as_index = False).agg({\"Actual_Impact\":\"mean\",\"Call Volume\":\"mean\"}).reset_index(drop=True)\n",
        "      return historic_holiday_impact\n",
        "\n",
        "  @tool\n",
        "  def final_adjustment(input: str) -> str:\n",
        "\n",
        "      \"\"\"\n",
        "      Performs a final adjustment on the holiday-forecasted call volumes by incorporating\n",
        "      the difference between actual historical impact and the impact already captured.\n",
        "      \"\"\"\n",
        "      global adjust_df\n",
        "      adjust_df = forecast_holiday_impact.merge(historic_holiday_impact, on=\"Holiday\", how = \"left\")\n",
        "      adjust_df['Impact_Not_Captured'] = adjust_df['Actual_Impact'] - adjust_df['Impact_Captured']\n",
        "      adjust_df['FestiVcast_Adjusted_Forecast'] = np.where(adjust_df['Impact_Not_Captured']>0, adjust_df['Forecast']*(1+(adjust_df['Impact_Not_Captured'])/100), adjust_df['Forecast'])\n",
        "      return adjust_df\n",
        "\n",
        "\n",
        "  tools = [final_adjustment, holiday_impact,identify_holidays]\n",
        "  llm = ChatVertexAI(\n",
        "      model=\"gemini-2.5-pro\",\n",
        "      project=\"steady-bonsai-467007-g0\",\n",
        "      location=\"us-central1\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0.7,\n",
        "      credentials=credentials\n",
        "  )\n",
        "  bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "  agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "  graph = StateGraph(AgentState)\n",
        "  graph.add_node(\"agent\", agent_node)\n",
        "  graph.set_entry_point(\"agent\")\n",
        "\n",
        "  runnable = graph.compile()\n",
        "  prompt = \"identify the holidays present in 'forecast_df' and thenEvaluate the actual impact of holidays on call volume and finally  Performs a final adjustment on the holiday-forecasted call volumes\"\n",
        "  output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "  print(\"\\nFinal output from agent:\\n\")\n",
        "  for msg in output[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "  return None\n",
        "\n",
        "###########################################################################################################################\n",
        "#####################################...............SesoCast..............###############################################\n",
        "###########################################################################################################################\n",
        "def Sesocast(state:Agentic_AI):\n",
        "  @tool\n",
        "  def get_historical_periods_dynamic_actual(input: str) -> str:\n",
        "      \"\"\"\n",
        "      Extracts the same date range in previous years from a DataFrame, dynamically determining available years.\n",
        "      Returns:\n",
        "          dict: A dictionary where keys are years and values are DataFrames\n",
        "                containing the corresponding period. Returns an empty dictionary if there are issues.\n",
        "      \"\"\"\n",
        "      global forecast_df, model_data,final_last_28_days\n",
        "      df = model_data.iloc[-28:].copy()\n",
        "      df_history =  model_data.copy()\n",
        "      date_column='Date'\n",
        "      start_date=None\n",
        "      end_date=None\n",
        "\n",
        "      df_history.rename(columns={'REPORT DT':'Date', 'TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "      df[date_column] = pd.to_datetime(df[date_column])\n",
        "      # Determine start and end dates if not provided\n",
        "      if start_date is None or end_date is None:\n",
        "          end_date = df[date_column].max()\n",
        "          start_date = df[date_column].min()\n",
        "      else:\n",
        "          start_date = pd.to_datetime(start_date)\n",
        "          end_date = pd.to_datetime(end_date)\n",
        "      # Calculate the date range\n",
        "      date_range = end_date - start_date\n",
        "      if date_range.days < 0:\n",
        "          print(\"Error: End date is earlier than start date.\")\n",
        "      historical_periods = {}\n",
        "      current_year = end_date.year # Use the end date year as the \"current\" year\n",
        "      available_years = sorted(df_history[date_column].dt.year.unique(), reverse=True)\n",
        "      # Iterate through available years *excluding* the current year\n",
        "      for year in available_years:\n",
        "          if year == current_year:\n",
        "              continue #skip current year\n",
        "          # Calculate the start and end dates for the current year\n",
        "          year_start_date = pd.to_datetime(f'{year}-{start_date.month}-{start_date.day}')\n",
        "          year_end_date = pd.to_datetime(f'{year}-{end_date.month}-{end_date.day}')\n",
        "          # Filter the Dataframe for the current year period\n",
        "          year_df = df_history[(df_history[date_column] >= year_start_date) & (df_history[date_column] <= year_end_date)].copy()\n",
        "          if not year_df.empty:\n",
        "              historical_periods[year] = year_df\n",
        "          else:\n",
        "              print(f'No data found for {year}.')\n",
        "      historical_periods_yearly = pd.DataFrame()\n",
        "      last_28days_dict = historical_periods.copy()\n",
        "      counter = 0\n",
        "      final_last_28_days = pd.DataFrame()\n",
        "      for i in last_28days_dict.keys():\n",
        "          if counter<3:\n",
        "              globals()[f\"last_28days_{i}\"] = last_28days_dict[i]\n",
        "          else:\n",
        "              break\n",
        "          final_last_28_days = pd.concat([final_last_28_days,globals()[f\"last_28days_{i}\"]], ignore_index = True)\n",
        "          final_last_28_days['Year'] = final_last_28_days['Date'].dt.year\n",
        "      return final_last_28_days\n",
        "\n",
        "\n",
        "  @tool\n",
        "  def get_historical_periods_dynamic_forecast(input: str) -> str:\n",
        "\n",
        "      \"\"\"\n",
        "      Forecast is Extracted for the same date range from forecast dataframe, dynamically determining available years.\n",
        "      Returns:\n",
        "          dict: A dictionary where keys are years and values are DataFrames\n",
        "                containing the corresponding period. Returns an empty dictionary if there are issues.\n",
        "      \"\"\"\n",
        "      global forecast_df, model_data,final_next_28_days\n",
        "      df = forecast_df.copy()\n",
        "      df_history =  model_data.copy()\n",
        "      date_column='Date'\n",
        "      start_date=None\n",
        "      end_date=None\n",
        "\n",
        "      df_history.rename(columns={'REPORT_DT': 'Date', 'TOTAL_OFFERED_CALL_VOLUME':'Call Volume'},inplace=True)\n",
        "      df[date_column] = pd.to_datetime(df[date_column])\n",
        "      # Determine start and end dates if not provided\n",
        "      if start_date is None or end_date is None:\n",
        "          end_date = df[date_column].max()\n",
        "          start_date = df[date_column].min()\n",
        "      else:\n",
        "          start_date = pd.to_datetime(start_date)\n",
        "          end_date = pd.to_datetime(end_date)\n",
        "      # Calculate the date range\n",
        "      date_range = end_date - start_date\n",
        "      if date_range.days < 0:\n",
        "          print(\"Error: End date is earlier than start date.\")\n",
        "      historical_periods = {}\n",
        "      current_year = end_date.year # Use the end_date year as the \"current\" year\n",
        "      available_years = sorted(df_history[date_column].dt.year.unique(), reverse=True)\n",
        "      # Iterate through available years excluding the \"current\" year\n",
        "      for year in available_years:\n",
        "          if year == current_year:\n",
        "              continue #skip current year\n",
        "          year_start_date = pd.to_datetime(f'{year}-{start_date.month}-{start_date.day}')\n",
        "          year_end_date = pd.to_datetime(f'{year}-{end_date.month}-{end_date.day}')\n",
        "          year_df = df_history[(df_history[date_column] >= year_start_date) & (df_history[date_column] <= year_end_date)].copy()\n",
        "          if not year_df.empty:\n",
        "              historical_periods[year] = year_df\n",
        "      else:\n",
        "          historical_periods[year] = pd.DataFrame()\n",
        "      next_28days_dict = historical_periods.copy()\n",
        "      counter = 0\n",
        "      # Initialize an empty DataFrame\n",
        "      final_next_28_days = pd.DataFrame()\n",
        "      for i in next_28days_dict.keys():\n",
        "          if counter<3:\n",
        "              globals()[f\"next_28days_{i}\"] = next_28days_dict[i]\n",
        "              counter+=1\n",
        "          else:\n",
        "              break\n",
        "          final_next_28_days = pd.concat([final_next_28_days,globals()[f\"next_28days_{i}\"]], ignore_index = True)\n",
        "          final_next_28_days['Year'] = final_next_28_days['Date'].dt.year\n",
        "      return final_next_28_days\n",
        "\n",
        "  @tool\n",
        "  def Final_adjustment_Seso(input: str) -> str:\n",
        "    \"\"\"\n",
        "      Applies a last-mile seasonal adjustment to the forecasted call volumes based on\n",
        "      day-of-week (DOW) trends observed in the last 28 days vs the upcoming 28 days.\n",
        "    \"\"\"\n",
        "    global forecast_df, model_data,final_next_28_days,forecast_merged,final_last_28_days\n",
        "    final_next_28_dow_avg = final_next_28_days.groupby([\"Year\",\"DAY_OF_WEEK\"], as_index = False).agg({\"Call Volume\":\"mean\"})\n",
        "    final_next_28_dow_avg = final_next_28_dow_avg.rename(columns = {'Call Volume':'actual_offered_next'})\n",
        "    final_last_28_dow_avg = final_last_28_days.groupby([\"Year\",\"DAY_OF_WEEK\"], as_index = False).agg({\"Call Volume\":\"mean\"})\n",
        "    final_last_28_dow_avg = final_last_28_dow_avg.rename(columns = {'Call Volume':'actual_offered_last'})\n",
        "    final_seasonal_comparison_df = final_next_28_dow_avg.merge(final_last_28_dow_avg, on = [\"Year\",\"DAY_OF_WEEK\"], how = \"inner\")\n",
        "    final_seasonal_comparison_df[\"Seasonal_Factor\"] = (final_seasonal_comparison_df[\"actual_offered_next\"]/ final_seasonal_comparison_df[\"actual_offered_last\"])\n",
        "    final_seasonality_dim = final_seasonal_comparison_df.groupby([\"DAY_OF_WEEK\"], as_index = False).agg({\"Seasonal_Factor\":\"mean\"})\n",
        "\n",
        "    forecast_df['DAY_OF_WEEK'] = pd.to_datetime(forecast_df['Date']).dt.day_name()\n",
        "\n",
        "    forecast_merged = forecast_df.merge(final_seasonality_dim,on=['DAY_OF_WEEK'],how='inner')\n",
        "    forecast_merged['LM_Seasonal_Adjustment'] = forecast_merged['Forecast'] * forecast_merged['Seasonal_Factor']\n",
        "    forecast_merged = forecast_merged[['Date','DAY_OF_WEEK','Forecast','Seasonal_Factor','LM_Seasonal_Adjustment']]\n",
        "    return forecast_merged\n",
        "\n",
        "\n",
        "  tools = [Final_adjustment_Seso, get_historical_periods_dynamic_forecast,get_historical_periods_dynamic_actual]\n",
        "  llm = ChatVertexAI(\n",
        "      model=\"gemini-2.5-pro\",\n",
        "      project=\"steady-bonsai-467007-g0\",\n",
        "      location=\"us-central1\",\n",
        "      max_output_tokens=1024,\n",
        "      temperature=0.7,\n",
        "      credentials=credentials\n",
        "  )\n",
        "  bound_llm = llm.bind_tools(tools)\n",
        "\n",
        "  agent_node = create_react_agent(bound_llm, tools=tools, state_schema=AgentState)\n",
        "  graph = StateGraph(AgentState)\n",
        "  graph.add_node(\"agent\", agent_node)\n",
        "  graph.set_entry_point(\"agent\")\n",
        "\n",
        "  runnable = graph.compile()\n",
        "  prompt = \"extract the same date range in previous years from 'model_data' and also  Extract for the same date range from forecast dataframe 'forecast_df' and finally Apply a last-mile seasonal adjustment to the forecasted call volumes \"\n",
        "  output = runnable.invoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "\n",
        "\n",
        "  print(\"\\nFinal output from agent:\\n\")\n",
        "  for msg in output[\"messages\"]:\n",
        "      if hasattr(msg, \"name\"):\n",
        "          print(f\"[TOOL: {msg.name}] {msg.content}\")\n",
        "  return None\n",
        "\n",
        "################################################################################################################################################\n",
        "graph = StateGraph(Agentic_AI)\n",
        "graph.add_node(\"Corecast\", Corecast)\n",
        "graph.add_node(\"Festivcast\", FestivCast)\n",
        "graph.add_node(\"SesoCast\", Sesocast)\n",
        "graph.set_entry_point(\"Corecast\")\n",
        "graph.add_edge(\"Corecast\",\"Festivcast\")\n",
        "graph.add_edge(\"Corecast\",\"SesoCast\")\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "runnable = app.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld3qZqMooTxD",
        "outputId": "8f50f39f-9993-478d-d3ca-537c16ce92fa"
      },
      "id": "ld3qZqMooTxD",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-114-1638180893.py:85: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.84579339 0.56467306 0.03044069 ... 0.3331664  0.54442696 0.41865789]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 502ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-114-1638180893.py:159: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.84579339 0.56467306 0.03044069 ... 0.54757476 0.61865074 0.2702461 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  model_data_encoded_scaled.loc[:, ['TOTAL_OFFERED_CALL_VOLUME', 'HOLIDAY_ENCODED']] = scaler.fit_transform(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 430ms/step\n",
            "\n",
            "Final output from agent:\n",
            "\n",
            "[TOOL: None] Preprocesses the dataframe with  'model_data' and Predicts future call volumes using a pre-trained LSTM model with 'model_data_encoded' \n",
            "[TOOL: None] \n",
            "[TOOL: preprocess]             TOTAL_OFFERED_CALL_VOLUME  DAY_OF_WEEK_SIN  DAY_OF_WEEK_COS  \\\n",
            "REPORT_DT                                                                 \n",
            "2020-07-01                      32654         0.974928        -0.222521   \n",
            "2020-07-02                      24795         0.433884        -0.900969   \n",
            "2020-07-03                       9860        -0.433884        -0.900969   \n",
            "2020-07-04                      14390        -0.974928        -0.222521   \n",
            "2020-07-05                      30575        -0.781831         0.623490   \n",
            "...                               ...              ...              ...   \n",
            "2025-06-26                      34068         0.433884        -0.900969   \n",
            "2025-06-27                      22737        -0.433884        -0.900969   \n",
            "2025-06-28                      18323        -0.974928        -0.222521   \n",
            "2025-06-29                      24229        -0.781831         0.623490   \n",
            "2025-06-30                      20713         0.000000         1.000000   \n",
            "\n",
            "            DAY_OF_MONTH_SIN  DAY_OF_MONTH_COS     MONTH_SIN  MONTH_COS  \\\n",
            "REPORT_DT                                                                 \n",
            "2020-07-01          0.201299          0.979530 -5.000000e-01  -0.866025   \n",
            "2020-07-02          0.394356          0.918958 -5.000000e-01  -0.866025   \n",
            "2020-07-03          0.571268          0.820763 -5.000000e-01  -0.866025   \n",
            "2020-07-04          0.724793          0.688967 -5.000000e-01  -0.866025   \n",
            "2020-07-05          0.848644          0.528964 -5.000000e-01  -0.866025   \n",
            "...                      ...               ...           ...        ...   \n",
            "2025-06-26         -0.848644          0.528964  1.224647e-16  -1.000000   \n",
            "2025-06-27         -0.724793          0.688967  1.224647e-16  -1.000000   \n",
            "2025-06-28         -0.571268          0.820763  1.224647e-16  -1.000000   \n",
            "2025-06-29         -0.394356          0.918958  1.224647e-16  -1.000000   \n",
            "2025-06-30         -0.201299          0.979530  1.224647e-16  -1.000000   \n",
            "\n",
            "             QUARTER_SIN   QUARTER_COS  is_sunday  is_monday  is_weekend  \\\n",
            "REPORT_DT                                                                  \n",
            "2020-07-01 -1.000000e+00 -1.836970e-16          0          0           0   \n",
            "2020-07-02 -1.000000e+00 -1.836970e-16          0          0           0   \n",
            "2020-07-03 -1.000000e+00 -1.836970e-16          0          0           0   \n",
            "2020-07-04 -1.000000e+00 -1.836970e-16          0          0           1   \n",
            "2020-07-05 -1.000000e+00 -1.836970e-16          1          0           1   \n",
            "...                  ...           ...        ...        ...         ...   \n",
            "2025-06-26  1.224647e-16 -1.000000e+00          0          0           0   \n",
            "2025-06-27  1.224647e-16 -1.000000e+00          0          0           0   \n",
            "2025-06-28  1.224647e-16 -1.000000e+00          0          0           1   \n",
            "2025-06-29  1.224647e-16 -1.000000e+00          1          0           1   \n",
            "2025-06-30  1.224647e-16 -1.000000e+00          0          1           0   \n",
            "\n",
            "            HOLIDAY_ENCODED  \n",
            "REPORT_DT                    \n",
            "2020-07-01     23284.792028  \n",
            "2020-07-02     23284.792028  \n",
            "2020-07-03     23284.792028  \n",
            "2020-07-04     23211.000000  \n",
            "2020-07-05     23284.792028  \n",
            "...                     ...  \n",
            "2025-06-26     23284.792028  \n",
            "2025-06-27     23284.792028  \n",
            "2025-06-28     23284.792028  \n",
            "2025-06-29     23284.792028  \n",
            "2025-06-30     23284.792028  \n",
            "\n",
            "[1826 rows x 13 columns]\n",
            "[TOOL: LSTM_Prediction]           Date      Forecast\n",
            "0   2025-07-01  18657.938246\n",
            "1   2025-07-02  19991.647395\n",
            "2   2025-07-03  19417.162908\n",
            "3   2025-07-04  21643.090549\n",
            "4   2025-07-05  13856.495825\n",
            "..         ...           ...\n",
            "175 2025-12-23  23944.465259\n",
            "176 2025-12-24  23508.302619\n",
            "177 2025-12-25  20888.359085\n",
            "178 2025-12-26  23039.292060\n",
            "179 2025-12-27  19118.620600\n",
            "\n",
            "[180 rows x 2 columns]\n",
            "[TOOL: None] The `preprocess` function has successfully processed the 'model_data' and the `LSTM_Prediction` function has provided a forecast for the next 180 days, starting from 2025-07-01. The forecast data is now available for review.\n",
            "[TOOL: None] Calculate the Mean Absolute Percentage Error (MAPE) between predicted and actual call volumes for the last 7 days with 'model_data' \n",
            "[TOOL: None] \n",
            "[TOOL: Last_week_Mape] 28.213471296479355\n",
            "[TOOL: None] The Mean Absolute Percentage Error (MAPE) for the last 7 days is 28.21%. This means that on average, the predictions for the last week were off by about 28.21% from the actual call volumes.\n",
            "No data found for 2020.\n",
            "\n",
            "Final output from agent:\n",
            "\n",
            "[TOOL: None] identify the holidays present in 'forecast_df' and thenEvaluate the actual impact of holidays on call volume and finally  Performs a final adjustment on the holiday-forecasted call volumes\n",
            "[TOOL: None] \n",
            "[TOOL: identify_holidays]         Date           Holiday Day of Week      Forecast    dow_avg_3w  \\\n",
            "0 2025-07-04  Independence Day      Friday  21643.090549  27750.333333   \n",
            "1 2025-09-01         Labor Day      Monday  16431.670677           NaN   \n",
            "2 2025-10-13      Columbus Day      Monday  27283.933681           NaN   \n",
            "3 2025-10-31         Halloween      Friday  28916.843330           NaN   \n",
            "4 2025-11-11      Veterans Day     Tuesday  34469.892887           NaN   \n",
            "5 2025-11-27  Thanksgiving Day    Thursday  30024.826141           NaN   \n",
            "6 2025-11-28      Black Friday      Friday  27103.125992           NaN   \n",
            "7 2025-12-01      Cyber Monday      Monday  33119.320706           NaN   \n",
            "8 2025-12-24     Christmas Eve   Wednesday  23508.302619           NaN   \n",
            "9 2025-12-25     Christmas Day    Thursday  20888.359085           NaN   \n",
            "\n",
            "   Impact_Captured  \n",
            "0           -22.01  \n",
            "1              NaN  \n",
            "2              NaN  \n",
            "3              NaN  \n",
            "4              NaN  \n",
            "5              NaN  \n",
            "6              NaN  \n",
            "7              NaN  \n",
            "8              NaN  \n",
            "9              NaN  \n",
            "[TOOL: holiday_impact]                        Holiday  Actual_Impact   Call Volume\n",
            "0                 Black Friday     -28.168000  18145.000000\n",
            "1                Christmas Day      28.028000  28821.000000\n",
            "2                Christmas Eve     -23.530000  16877.600000\n",
            "3                 Columbus Day       2.870000  19896.800000\n",
            "4                 Cyber Monday      32.690000  28951.800000\n",
            "5                       Easter      15.014000  27125.600000\n",
            "6                    Halloween      -3.562000  23450.400000\n",
            "7             Independence Day      26.630000  23211.000000\n",
            "8                   Juneteenth       4.512000  21551.600000\n",
            "9                    Labor Day     -21.578000  17450.200000\n",
            "10  Martin Luther King Jr. Day      22.532000  28489.200000\n",
            "11                Memorial Day       2.670000  23497.000000\n",
            "12              New Year's Day      -5.304000  23193.800000\n",
            "13              New Year's Eve       7.382000  20729.400000\n",
            "14                  Normal Day       4.952162  23284.792028\n",
            "15             President's Day     -15.742000  21517.800000\n",
            "16           St. Patrick's Day      27.028000  21237.000000\n",
            "17            Thanksgiving Day      13.412000  24315.800000\n",
            "18             Valentine's Day     -15.342000  18520.800000\n",
            "19                Veterans Day      22.126000  26574.800000\n",
            "[TOOL: final_adjustment]         Date           Holiday Day of Week      Forecast    dow_avg_3w  \\\n",
            "0 2025-07-04  Independence Day      Friday  21643.090549  27750.333333   \n",
            "1 2025-09-01         Labor Day      Monday  16431.670677           NaN   \n",
            "2 2025-10-13      Columbus Day      Monday  27283.933681           NaN   \n",
            "3 2025-10-31         Halloween      Friday  28916.843330           NaN   \n",
            "4 2025-11-11      Veterans Day     Tuesday  34469.892887           NaN   \n",
            "5 2025-11-27  Thanksgiving Day    Thursday  30024.826141           NaN   \n",
            "6 2025-11-28      Black Friday      Friday  27103.125992           NaN   \n",
            "7 2025-12-01      Cyber Monday      Monday  33119.320706           NaN   \n",
            "8 2025-12-24     Christmas Eve   Wednesday  23508.302619           NaN   \n",
            "9 2025-12-25     Christmas Day    Thursday  20888.359085           NaN   \n",
            "\n",
            "   Impact_Captured  Actual_Impact  Call Volume  Impact_Not_Captured  \\\n",
            "0           -22.01         26.630      23211.0                48.64   \n",
            "1              NaN        -21.578      17450.2                  NaN   \n",
            "2              NaN          2.870      19896.8                  NaN   \n",
            "3              NaN         -3.562      23450.4                  NaN   \n",
            "4              NaN         22.126      26574.8                  NaN   \n",
            "5              NaN         13.412      24315.8                  NaN   \n",
            "6              NaN        -28.168      18145.0                  NaN   \n",
            "7              NaN         32.690      28951.8                  NaN   \n",
            "8              NaN        -23.530      16877.6                  NaN   \n",
            "9              NaN         28.028      28821.0                  NaN   \n",
            "\n",
            "   FestiVcast_Adjusted_Forecast  \n",
            "0                  32170.289792  \n",
            "1                  16431.670677  \n",
            "2                  27283.933681  \n",
            "3                  28916.843330  \n",
            "4                  34469.892887  \n",
            "5                  30024.826141  \n",
            "6                  27103.125992  \n",
            "7                  33119.320706  \n",
            "8                  23508.302619  \n",
            "9                  20888.359085  \n",
            "[TOOL: None] Following are the results of the analysis performed on the forecast_df:\n",
            "\n",
            "**Holidays Identified in the Forecast Dataset:**\n",
            "\n",
            "```\n",
            "        Date           Holiday Day of Week      Forecast    dow_avg_3w  Impact_Captured\n",
            "0 2025-07-04  Independence Day      Friday  21643.090549  27750.333333           -22.01\n",
            "1 2025-09-01         Labor Day      Monday  16431.670677           NaN              NaN\n",
            "2 2025-10-13      Columbus Day      Monday  27283.933681           NaN              NaN\n",
            "3 2025-10-31         Halloween      Friday  28916.843330           NaN              NaN\n",
            "4 2025-11-11      Veterans Day     Tuesday  34469.892887           NaN              NaN\n",
            "5 2025-11-27  Thanksgiving Day    Thursday  30024.826141           NaN              NaN\n",
            "6 2025-11-28      Black Friday      Friday  27103.125992           NaN              NaN\n",
            "7 2025-12-01      Cyber Monday      Monday  33119.320706           NaN              NaN\n",
            "8 2025-12-24     Christmas Eve   Wednesday  23508.3026\n",
            "\n",
            "Final output from agent:\n",
            "\n",
            "[TOOL: None] extract the same date range in previous years from 'model_data' and also  Extract for the same date range from forecast dataframe 'forecast_df' and finally Apply a last-mile seasonal adjustment to the forecasted call volumes \n",
            "[TOOL: None] \n",
            "[TOOL: get_historical_periods_dynamic_actual]      index       Date  Call Volume DAY_OF_WEEK  DAY_OF_MONTH  MONTH  QUARTER  \\\n",
            "0     1433 2024-06-03        33777      Monday             3      6        2   \n",
            "1     1434 2024-06-04        28891     Tuesday             4      6        2   \n",
            "2     1435 2024-06-05        15456   Wednesday             5      6        2   \n",
            "3     1436 2024-06-06        13212    Thursday             6      6        2   \n",
            "4     1437 2024-06-07        22224      Friday             7      6        2   \n",
            "..     ...        ...          ...         ...           ...    ...      ...   \n",
            "107    360 2021-06-26        29817    Saturday            26      6        2   \n",
            "108    361 2021-06-27        20969      Sunday            27      6        2   \n",
            "109    362 2021-06-28        11869      Monday            28      6        2   \n",
            "110    363 2021-06-29        36810     Tuesday            29      6        2   \n",
            "111    364 2021-06-30        26340   Wednesday            30      6        2   \n",
            "\n",
            "     YEAR  Year  \n",
            "0    2024  2024  \n",
            "1    2024  2024  \n",
            "2    2024  2024  \n",
            "3    2024  2024  \n",
            "4    2024  2024  \n",
            "..    ...   ...  \n",
            "107  2021  2021  \n",
            "108  2021  2021  \n",
            "109  2021  2021  \n",
            "110  2021  2021  \n",
            "111  2021  2021  \n",
            "\n",
            "[112 rows x 9 columns]\n",
            "[TOOL: get_historical_periods_dynamic_forecast]      index       Date  Call Volume DAY_OF_WEEK  DAY_OF_MONTH  MONTH  QUARTER  \\\n",
            "0     1461 2024-07-01        21997      Monday             1      7        3   \n",
            "1     1462 2024-07-02        28956     Tuesday             2      7        3   \n",
            "2     1463 2024-07-03        31359   Wednesday             3      7        3   \n",
            "3     1464 2024-07-04        22472    Thursday             4      7        3   \n",
            "4     1465 2024-07-05        31704      Friday             5      7        3   \n",
            "..     ...        ...          ...         ...           ...    ...      ...   \n",
            "535    905 2022-12-23        32833      Friday            23     12        4   \n",
            "536    906 2022-12-24        13158    Saturday            24     12        4   \n",
            "537    907 2022-12-25        29309      Sunday            25     12        4   \n",
            "538    908 2022-12-26        15970      Monday            26     12        4   \n",
            "539    909 2022-12-27        15938     Tuesday            27     12        4   \n",
            "\n",
            "     YEAR  Year  \n",
            "0    2024  2024  \n",
            "1    2024  2024  \n",
            "2    2024  2024  \n",
            "3    2024  2024  \n",
            "4    2024  2024  \n",
            "..    ...   ...  \n",
            "535  2022  2022  \n",
            "536  2022  2022  \n",
            "537  2022  2022  \n",
            "538  2022  2022  \n",
            "539  2022  2022  \n",
            "\n",
            "[540 rows x 9 columns]\n",
            "[TOOL: Final_adjustment_Seso]           Date DAY_OF_WEEK      Forecast  Seasonal_Factor  \\\n",
            "0   2025-07-01     Tuesday  18657.938246         0.930398   \n",
            "1   2025-07-02   Wednesday  19991.647395         0.886288   \n",
            "2   2025-07-03    Thursday  19417.162908         1.219900   \n",
            "3   2025-07-04      Friday  21643.090549         1.138394   \n",
            "4   2025-07-05    Saturday  13856.495825         1.393073   \n",
            "..         ...         ...           ...              ...   \n",
            "175 2025-12-23     Tuesday  23944.465259         0.930398   \n",
            "176 2025-12-24   Wednesday  23508.302619         0.886288   \n",
            "177 2025-12-25    Thursday  20888.359085         1.219900   \n",
            "178 2025-12-26      Friday  23039.292060         1.138394   \n",
            "179 2025-12-27    Saturday  19118.620600         1.393073   \n",
            "\n",
            "     LM_Seasonal_Adjustment  \n",
            "0              17359.315050  \n",
            "1              17718.358044  \n",
            "2              23686.998002  \n",
            "3              24638.354299  \n",
            "4              19303.116799  \n",
            "..                      ...  \n",
            "175            22277.891087  \n",
            "176            20835.127520  \n",
            "177            25481.710292  \n",
            "178            26227.781069  \n",
            "179            26633.643248  \n",
            "\n",
            "[180 rows x 5 columns]\n",
            "[TOOL: None] Following your request, I have successfully performed the following actions:\n",
            "\n",
            "1.  Extracted the historical data from the `model_data` for the same date range in previous years. The resulting data contains 112 rows and 9 columns, with data for the years 2021\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}